{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"get_packages.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, mean_squared_error, r2_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from pickle import TRUE\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os\n",
    "from skopt import BayesSearchCV  # need scikit-optimize\n",
    "from skopt.space import Real, Integer\n",
    "import xbbg\n",
    "import blp\n",
    "from sklearn import preprocessing\n",
    "import openpyxl\n",
    "import plotly.express as px\n",
    "import statsmodels\n",
    "from xbbg import blp\n",
    "import datetime\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from pandas.tseries.offsets import BDay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = date.today()\n",
    "end_date = today.strftime(\"%Y%m%d\")\n",
    "strt_date=\"20241030\"\n",
    "std_size = 0.03\n",
    "concentration_size = 0.05\n",
    "step_size = 0.005\n",
    "TE_upper_bound = 0.012\n",
    "TE_lower_bound = 0.008\n",
    "features_weight = 0.33\n",
    "multiplier = 2\n",
    "carry_cost_lim = 0.003\n",
    "#start_date = 1/1/2003\n",
    "\n",
    "REER_lag = 22\n",
    "TB_lag = 30\n",
    "GDP_lag = 120\n",
    "CPI_lag = 30\n",
    "\n",
    "Adj_REER = [\"REER\", \"Conditional REER\", \"Symmetrical REER\"]\n",
    "Carry = [\"Nominal Carry\", \"Real Carry\"]\n",
    "Conviction = [\"Awa\", \"Agn\"]\n",
    "\n",
    "currencies = [\"BRL\", \"CLP\", \"CNY\", \"COP\", \"CZK\", \"HUF\", \"IDR\", \"MYR\", \"MXN\", \"PEN\", \"PHP\", \"PLN\", \"RON\", \"RUB\", \"ZAR\", \"THB\", \"TRY\", \"INR\", \"SGD\", \"TWD\", \"KRW\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPOT PRICE\n",
    "from blp import blp\n",
    "bquery = blp.BlpQuery().start()\n",
    "spot_query = bquery.bdh(\n",
    "        [\"BRL BGN Curncy\", \"CLP BGN Curncy\", \"CNY CMPN Curncy\", \"COP REGN Curncy\", \"CZK BGN Curncy\", \"HUF BGN Curncy\", \"IDR CMPN Curncy\", \"MYR CMPN Curncy\", \"MXN BGN Curncy\", \"PEN BGN Curncy\", \"PHP CMPN Curncy\", \"PLN BGN Curncy\", \"RON BGN Curncy\", \"RUB BGN Curncy\", \"ZAR BGN Curncy\", \"THB BGN Curncy\", \"TRY BGN Curncy\", \"INR CMPN Curncy\", \"SGD BGN Curncy\", \"TWD BGN Curncy\", \"KRW CMPN Curncy\"],\n",
    "        [\"PX_LAST\"],\n",
    "        start_date= strt_date, \n",
    "        end_date= end_date, \n",
    "        options={\"adjustmentSplit\": True, \"CDR\":\"5D\"})\n",
    "\n",
    "spot_query['security_short'] = spot_query['security'].str[:3]\n",
    "\n",
    "spot = spot_query.pivot_table(index='date', columns='security_short', values='PX_LAST', aggfunc='first')\n",
    "spot.reset_index( inplace=True)\n",
    "spot.rename(columns={'date':'DATE'}, inplace=True)\n",
    "spot['DATE'] = pd.to_datetime(spot['DATE'])\n",
    "spot.sort_values(by='DATE', ascending=False, inplace=True)\n",
    "spot.dropna(inplace=True)\n",
    "\n",
    "# Extract relevant columns\n",
    "columns = [\"DATE\"] + currencies\n",
    "spot_subset = spot[columns]\n",
    "\n",
    "# Calculate daily returns\n",
    "spot_subset.set_index(\"DATE\", inplace=True)\n",
    "daily_return = spot_subset.shift(-1)/spot_subset  -1\n",
    "daily_return.reset_index(inplace=True)\n",
    "#daily_return.dropna(inplace=True)\n",
    "spot_return = daily_return.melt(id_vars=[\"DATE\"], var_name=\"Currency\", value_name=\"Daily_Return\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>Currency</th>\n",
       "      <th>MOV_AVG_5D</th>\n",
       "      <th>MOV_AVG_20D</th>\n",
       "      <th>Momentum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-12-06</td>\n",
       "      <td>THB</td>\n",
       "      <td>34.3190</td>\n",
       "      <td>34.5540</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-12-06</td>\n",
       "      <td>CZK</td>\n",
       "      <td>23.8813</td>\n",
       "      <td>23.9580</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-12-06</td>\n",
       "      <td>TRY</td>\n",
       "      <td>34.7416</td>\n",
       "      <td>34.5638</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-12-06</td>\n",
       "      <td>SGD</td>\n",
       "      <td>1.3429</td>\n",
       "      <td>1.3423</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-12-06</td>\n",
       "      <td>TWD</td>\n",
       "      <td>32.4850</td>\n",
       "      <td>32.4890</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>2024-10-30</td>\n",
       "      <td>TRY</td>\n",
       "      <td>34.2738</td>\n",
       "      <td>34.2391</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>2024-10-30</td>\n",
       "      <td>MYR</td>\n",
       "      <td>4.3619</td>\n",
       "      <td>4.3096</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>2024-10-30</td>\n",
       "      <td>KRW</td>\n",
       "      <td>1384.0800</td>\n",
       "      <td>1363.4000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>2024-10-30</td>\n",
       "      <td>INR</td>\n",
       "      <td>84.0798</td>\n",
       "      <td>84.0379</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>2024-10-30</td>\n",
       "      <td>BRL</td>\n",
       "      <td>5.7212</td>\n",
       "      <td>5.6342</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>588 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          DATE Currency  MOV_AVG_5D  MOV_AVG_20D  Momentum\n",
       "0   2024-12-06      THB     34.3190      34.5540        -1\n",
       "1   2024-12-06      CZK     23.8813      23.9580        -1\n",
       "2   2024-12-06      TRY     34.7416      34.5638         1\n",
       "3   2024-12-06      SGD      1.3429       1.3423         1\n",
       "4   2024-12-06      TWD     32.4850      32.4890        -1\n",
       "..         ...      ...         ...          ...       ...\n",
       "583 2024-10-30      TRY     34.2738      34.2391         1\n",
       "584 2024-10-30      MYR      4.3619       4.3096         1\n",
       "585 2024-10-30      KRW   1384.0800    1363.4000         1\n",
       "586 2024-10-30      INR     84.0798      84.0379         1\n",
       "587 2024-10-30      BRL      5.7212       5.6342         1\n",
       "\n",
       "[588 rows x 5 columns]"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bquery = blp.BlpQuery().start()\n",
    "MA_query = bquery.bdh(\n",
    "        [\"BRL Curncy\",\"CLP Curncy\",\"CNY Curncy\",\"COP Curncy\",\"CZK Curncy\",\"HUF Curncy\",\"IDR Curncy\",\"MYR Curncy\",\"MXN Curncy\",\"PEN Curncy\",\"PHP Curncy\",\"PLN Curncy\",\"RON Curncy\",\"RUB Curncy\",\"ZAR Curncy\",\"THB Curncy\",\"TRY Curncy\",\"INR Curncy\",\"SGD Curncy\",\"TWD Curncy\",\"KRW Curncy\"],\n",
    "        [\"MOV_AVG_5D\",\"MOV_AVG_20D\"],\n",
    "        start_date=strt_date,\n",
    "        end_date= end_date, \n",
    "        options={\"adjustmentSplit\": True, \"CDR\":\"5D\"})\n",
    "MA_query.rename(columns={'date':'DATE'}, inplace=True)\n",
    "MA_query['Currency'] = MA_query['security'].str[:3]\n",
    "MA_query.drop(columns=\"security\", inplace=True)\n",
    "MA_query['Momentum'] = np.where(MA_query['MOV_AVG_5D'] > MA_query['MOV_AVG_20D'], 1, -1)\n",
    "Momentum = MA_query[[\"DATE\", \"Currency\", \"MOV_AVG_5D\", \"MOV_AVG_20D\",\"Momentum\"]]\n",
    "Momentum['DATE'] = pd.to_datetime(Momentum['DATE'])\n",
    "Momentum.sort_values(by='DATE', ascending=False, inplace=True)\n",
    "Momentum.reset_index(drop=True, inplace=True)\n",
    "#Momentum.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_momentum_dict(momentum_df):\n",
    "    \"\"\"Creates a dictionary of DataFrames with momentum data organized by date.\n",
    "\n",
    "    Args:\n",
    "        momentum_df: The input DataFrame with 'DATE', 'Currency', 'MOV_AVG_5D', 'MOV_AVG_20D', and 'Momentum' columns.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary where keys are dates (YYYYMMDD strings) and values are DataFrames\n",
    "        with 'Currency' as index and 'MOV_AVG_5D', 'MOV_AVG_20D', and 'Momentum' as columns.\n",
    "    \"\"\"\n",
    "\n",
    "    momentum_dict = {}\n",
    "    for date, date_df in momentum_df.groupby('DATE'):\n",
    "        date_str = date.strftime('%Y%m%d')\n",
    "        \n",
    "        if date_str not in momentum_dict: #Create empty dataframes for dates to avoid errors if data is missing.\n",
    "            momentum_dict[date_str] = pd.DataFrame(index = currencies, columns=['MOV_AVG_5D', 'MOV_AVG_20D', 'Momentum'])\n",
    "\n",
    "\n",
    "\n",
    "        temp_df = date_df.set_index('Currency')\n",
    "\n",
    "\n",
    "        temp_df = temp_df.reindex(currencies)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        momentum_dict[date_str] = temp_df #\n",
    "\n",
    "\n",
    "    return momentum_dict\n",
    "\n",
    "\n",
    "momentum_dict = create_momentum_dict(Momentum) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3M Implied vol\n",
    "from blp import blp \n",
    "bquery = blp.BlpQuery().start()\n",
    "IMPVOL_query = bquery.bdh(\n",
    "        [\"USDBRLV3M Curncy\",\"USDCLPV3M Curncy\",\"USDCNYV3M Curncy\",\"USDCOPV3M Curncy\",\"USDCZKV3M Curncy\",\"USDHUFV3M Curncy\",\"USDIDRV3M Curncy\",\"USDMYRV3M Curncy\",\"USDMXNV3M Curncy\",\"USDPENV3M Curncy\",\"USDPHPV3M Curncy\",\"USDPLNV3M Curncy\",\"USDRONV3M Curncy\",\"USDRUBV3M Curncy\",\"USDZARV3M Curncy\",\"USDTHBV3M Curncy\",\"USDTRYV3M Curncy\",\"USDINRV3M Curncy\",\"USDSGDV3M Curncy\",\"USDTWDV3M Curncy\",\"USDKRWV3M Curncy\"],\n",
    "        [\"PX_LAST\"],\n",
    "        start_date= strt_date, \n",
    "        end_date= end_date, \n",
    "        options={\"adjustmentSplit\": True, \"CDR\":\"5D\"}) #\n",
    "\n",
    "IMPVOL_query.rename(columns={'date':'DATE', 'PX_LAST':'3M Implied Vol'}, inplace=True)\n",
    "\n",
    "conditions = [\n",
    "    (IMPVOL_query['security'] == 'USDBRLV3M Curncy'),\n",
    "    (IMPVOL_query['security'] == 'USDCLPV3M Curncy'),\n",
    "    (IMPVOL_query['security'] == 'USDCNYV3M Curncy'),\n",
    "    (IMPVOL_query['security'] == 'USDCOPV3M Curncy'),\n",
    "    (IMPVOL_query['security'] == 'USDCZKV3M Curncy'),\n",
    "    (IMPVOL_query['security'] == 'USDHUFV3M Curncy'),\n",
    "    (IMPVOL_query['security'] == 'USDIDRV3M Curncy'),\n",
    "    (IMPVOL_query['security'] == 'USDMYRV3M Curncy'),\n",
    "    (IMPVOL_query['security'] == 'USDMXNV3M Curncy'),\n",
    "    (IMPVOL_query['security'] == 'USDPENV3M Curncy'),\n",
    "    (IMPVOL_query['security'] == 'USDPHPV3M Curncy'),\n",
    "    (IMPVOL_query['security'] == 'USDPLNV3M Curncy'),\n",
    "    (IMPVOL_query['security'] == 'USDRONV3M Curncy'),\n",
    "    (IMPVOL_query['security'] == 'USDRUBV3M Curncy'),\n",
    "    (IMPVOL_query['security'] == 'USDZARV3M Curncy'),\n",
    "    (IMPVOL_query['security'] == 'USDTHBV3M Curncy'),\n",
    "    (IMPVOL_query['security'] == 'USDTRYV3M Curncy'),\n",
    "    (IMPVOL_query['security'] == 'USDINRV3M Curncy'),\n",
    "    (IMPVOL_query['security'] == 'USDSGDV3M Curncy'),\n",
    "    (IMPVOL_query['security'] == 'USDTWDV3M Curncy'),\n",
    "    (IMPVOL_query['security'] == 'USDKRWV3M Curncy'),\n",
    "]\n",
    "\n",
    "IMPVOL_query['Currency'] = np.select(conditions, currencies, default=None)\n",
    "IMPVOL_query.drop(columns=\"security\", inplace=True)\n",
    "IMPVOL_query.sort_values(by='DATE', ascending=False, inplace=True)\n",
    "IMPVOL_query=IMPVOL_query[['DATE','Currency','3M Implied Vol']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_volatility_dict(volatility_df):\n",
    "    \"\"\"Creates a dictionary of DataFrames with volatility data organized by date.\n",
    "\n",
    "    Args:\n",
    "        volatility_df: Input DataFrame with 'DATE', 'Currency', and '3M Implied Vol' columns.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with dates ('YYYYMMDD') as keys and DataFrames as values.\n",
    "        DataFrames have 'Currency' as index and '3M Implied Vol' as column.\n",
    "    \"\"\"\n",
    "\n",
    "    volatility_dict = {}\n",
    "\n",
    "    for date, date_df in volatility_df.groupby('DATE'):  # Group by date\n",
    "        date_str = date.strftime('%Y%m%d')\n",
    "\n",
    "        if date_str not in volatility_dict:\n",
    "             volatility_dict[date_str] = pd.DataFrame(index=currencies, columns=['3M Implied Vol'])\n",
    "\n",
    "\n",
    "\n",
    "        temp_df = date_df.set_index('Currency') # Set Currency as index\n",
    "\n",
    "        temp_df = temp_df.reindex(currencies)  # Reindex to ensure all currencies and order\n",
    "\n",
    "\n",
    "        volatility_dict[date_str] = temp_df\n",
    "\n",
    "\n",
    "    return volatility_dict\n",
    "\n",
    "volatility_dict = create_volatility_dict(IMPVOL_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n",
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n",
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n",
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n",
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n",
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n",
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n",
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n",
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n",
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n",
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n",
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n",
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n",
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n",
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n",
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n",
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n",
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n",
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n",
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n",
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n",
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n",
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n",
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n",
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n",
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n",
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n",
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n",
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n",
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n",
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n",
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n",
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n",
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n",
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n",
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n",
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n",
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas.tseries.offsets import BDay\n",
    "import numpy as np\n",
    "from blp import blp \n",
    "all_currencies = [\"BRL\",\"CLP\",\"CNY\",\"COP\",\"CZK\",\"HUF\",\"IDR\",\"MYR\",\"MXN\",\"PEN\",\"PHP\",\"PLN\",\"RON\",\"RUB\",\"ZAR\",\"THB\",\"TRY\",\"INR\",\"SGD\",\"TWD\",\"KRW\",\"UAH\",\"EGP\",\"EUR\",\"JPY\",\"USD\",\"GBP\",\"CAD\",\"ARS\",\"CHF\"]\n",
    "\n",
    "# Create an empty list to store the dataframes\n",
    "all_cpi_data = []\n",
    "#bquery = blp.BlpQuery().start()\n",
    "# Loop through the dates from 2020 to today\n",
    "start_date = pd.Timestamp('2018-01-01')\n",
    "end_date = pd.Timestamp('today') \n",
    "for date in pd.date_range(start=start_date, end=end_date, freq='MS'): # 'MS' for month start frequency\n",
    "    specific_date = date + pd.DateOffset(months=1) - pd.DateOffset(days=1)  # Get the last day of the month\n",
    "\n",
    "    begin = ((specific_date - pd.DateOffset(months=2)).replace(day=1) + pd.DateOffset(months=1) - pd.DateOffset(days=1) - BDay(1)).strftime('%Y%m%d')\n",
    "    end = ((specific_date - pd.DateOffset(months=1)).replace(day=1) + pd.DateOffset(months=1) - pd.DateOffset(days=1) - BDay(1)).strftime('%Y%m%d')\n",
    "\n",
    "    bquery = blp.BlpQuery().start()\n",
    "    CPI_query = bquery.bdh(\n",
    "            [\"BZPIIPCM Index\",\"CLINNSMO Index\",\"CNCPIMOM Index\",\"COCPIMOM Index\",\"CZCPMOM Index\",\"HUCPIMM Index\",\"IDCPIM Index\",\"MACPIMOM Index\",\"MXCPCHNG Index\",\"PRCPNONC Index\",\"PHC2MOM Index\",\"POCPIMOM Index\",\"ROCOPMOM Index\",\"RUCPIMOM Index\",\"SACPIMOM Index\",\"THCPIMOM Index\",\"TUCPIM Index\",\"INFUTOT Index\",\"SICPIMOM Index\",\"TWCPIMOM Index\",\"KOCPIMOM Index\",\"UACPTMOM Index\",\"EGCPMOM Index\",\"ECCPEMUM Index\",\"JNCPIMOM Index\",\"CPURNSA% Index\",\"UKRPCJMR Index\",\"CACPICHG Index\",\"ARNCNINX Index\",\"SZCPIMOM Index\"],\n",
    "            [\"PX_LAST\"],\n",
    "            start_date= begin,\n",
    "            end_date= end, \n",
    "            options={\"adjustmentSplit\": True, \"nonTradingDayFillOption\":\"ALL_CALENDAR_DAYS\", \"periodicitySelection\":\"MONTHLY\", 'nonTradingDayFillMethod':'NIL_VALUE'})\n",
    "    CPI_query.rename(columns={'PX_LAST':'CPI'}, inplace=True)\n",
    "\n",
    "    conditions = [\n",
    "    (CPI_query['security'] == 'BZPIIPCM Index'),\n",
    "    (CPI_query['security'] == 'CLINNSMO Index'),\n",
    "    (CPI_query['security'] == 'CNCPIMOM Index'),\n",
    "    (CPI_query['security'] == 'COCPIMOM Index'),\n",
    "    (CPI_query['security'] == 'CZCPMOM Index'),\n",
    "    (CPI_query['security'] == 'HUCPIMM Index'),\n",
    "    (CPI_query['security'] == 'IDCPIM Index'),\n",
    "    (CPI_query['security'] == 'MACPIMOM Index'),\n",
    "    (CPI_query['security'] == 'MXCPCHNG Index'),\n",
    "    (CPI_query['security'] == 'PRCPNONC Index'),\n",
    "    (CPI_query['security'] == 'PHC2MOM Index'),\n",
    "    (CPI_query['security'] == 'POCPIMOM Index'),\n",
    "    (CPI_query['security'] == 'ROCOPMOM Index'),\n",
    "    (CPI_query['security'] == 'RUCPIMOM Index'),\n",
    "    (CPI_query['security'] == 'SACPIMOM Index'),\n",
    "    (CPI_query['security'] == 'THCPIMOM Index'),\n",
    "    (CPI_query['security'] == 'TUCPIM Index'),\n",
    "    (CPI_query['security'] == 'INFUTOT Index'),\n",
    "    (CPI_query['security'] == 'SICPIMOM Index'),\n",
    "    (CPI_query['security'] == 'TWCPIMOM Index'),\n",
    "    (CPI_query['security'] == 'KOCPIMOM Index'),\n",
    "    (CPI_query['security'] == 'UACPTMOM Index'),\n",
    "    (CPI_query['security'] == 'EGCPMOM Index'),\n",
    "    (CPI_query['security'] == 'ECCPEMUM Index'),\n",
    "    (CPI_query['security'] == 'JNCPIMOM Index'),\n",
    "    (CPI_query['security'] == 'CPURNSA% Index'),\n",
    "    (CPI_query['security'] == 'UKRPCJMR Index'),\n",
    "    (CPI_query['security'] == 'CACPICHG Index'),\n",
    "    (CPI_query['security'] == 'ARNCNINX Index'),\n",
    "    (CPI_query['security'] == 'SZCPIMOM Index')\n",
    "    ]\n",
    "\n",
    "    CPI_query['Currency'] = np.select(conditions, all_currencies, default=None)\n",
    "    CPI_query.loc[CPI_query['Currency'] == 'INR', 'CPI'] = 100*(CPI_query['CPI']/185.8 -1)\n",
    "        \n",
    "    CPI_query=CPI_query[['Currency','CPI']]\n",
    "    CPI_query['Date'] = specific_date # Add a Date column\n",
    "\n",
    "    all_cpi_data.append(CPI_query) # Append the dataframe to the list\n",
    "\n",
    "\n",
    "# Concatenate all dataframes vertically\n",
    "final_cpi_data = pd.concat(all_cpi_data, ignore_index=True)\n",
    "\n",
    "CPI_query = final_cpi_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########  extract CPI from this \n",
    "tickers = [\n",
    "    \"BZPIIPCY Index\", \"CLINSYOY Index\", \"CNCPIY0Y Index\", \"COCPIY0Y Index\", \"CZCPIY0Y Index\", \n",
    "    \"HUCPIY Index\", \"IDCPIY Index\", \"INCPIY Index\", \"MACPIY0Y Index\", \"MXCPIY0Y Index\",\n",
    "    \"MYRCPYOY Index\", \"PRCPYOY Index\", \"PHCPIY Index\", \"PLCPIY0Y Index\", \"POCPIY0Y Index\", \n",
    "    \"ROCPIY0Y Index\", \"RUCPIY0Y Index\", \"SACPIYOY Index\", \"THCPIY0Y Index\", \"TUCPIY Index\", \n",
    "    \"TWCPIY0Y Index\", \"KOCPIY0Y Index\", \"UACPIY0Y Index\", \"EGCPIY0Y Index\", \"ECCPEGUY Index\", \n",
    "    \"JNCPIY0Y Index\", \"IW/FUTOTY Index\", \"SICPIY0Y Index\"\n",
    "]\n",
    "\n",
    "cpi_tickers = pd.DataFrame({'Ticker': tickers})\n",
    "cpi_value = CPI_query.loc[CPI_query['Currency'] == 'USD', 'CPI'].iloc[0]\n",
    "\n",
    "from blp import blp \n",
    "ticker_to_currency = {\n",
    "    \"BZPIIPCY Index\": \"BRL\",\n",
    "    \"CLINNSYO Index\": \"CLP\",\n",
    "    \"CNCPIYOY Index\": \"CNY\",\n",
    "    \"COCPIYOY Index\": \"COP\",\n",
    "    \"CZCPYOY Index\": \"CZK\",\n",
    "    \"HUCPIYY Index\": \"HUF\",\n",
    "    \"IDCPIY Index\": \"IDR\",\n",
    "    \"MACPIYOY Index\": \"CAD\",\n",
    "    \"MXCPYOY Index\": \"MXN\",\n",
    "    \"PRCPYOY Index\": \"PEN\",\n",
    "    \"PHC2II Index\": \"PHP\",\n",
    "    'MACPIYOY Index': 'MYR',\n",
    "    'SACPIYOY Index': 'ZAR',\n",
    "    \"POCPIYOY Index\": \"PLN\",\n",
    "    \"ROCOPYOY Index\": \"RON\",\n",
    "    \"RUCPIYOY Index\": \"RUB\",\n",
    "    \"SICPIYOY Index\": \"SGD\",\n",
    "    \"THCPIYOY Index\": \"THB\",\n",
    "    \"TUCPIY Index\": \"TRY\",\n",
    "    \"INFUTOTY Index\": \"INR\",\n",
    "    \"TWCPIYOY Index\": \"TWD\",\n",
    "    \"KOCPIYOY Index\": \"KRW\",\n",
    "    \"UACPTYOY Index\": \"UAH\",\n",
    "    \"EGCPYOY Index\": \"EGP\",\n",
    "    \"ECCPEMUY Index\": \"EUR\",\n",
    "    \"JNCPIYOY Index\": \"JPY\",\n",
    "    \"CPI YOY Index\": \"USD\"  # Assuming this is the US CPI YOY index\n",
    "}\n",
    "\n",
    "# Create an empty list to store the data\n",
    "data = []\n",
    "\n",
    "# Start a Bloomberg session\n",
    "\n",
    "# Iterate through the tickers and retrieve the last price\n",
    "for ticker, currency in ticker_to_currency.items():\n",
    "    try:\n",
    "        # Retrieve the last price\n",
    "        last_price_df = bquery.bdh([ticker], [\"last_price\"],\n",
    "            start_date= '20241001',\n",
    "            end_date = today.strftime(\"%Y%m%d\"), \n",
    "            options={\"adjustmentSplit\": True, \"nonTradingDayFillOption\":\"ALL_CALENDAR_DAYS\", \"periodicitySelection\":\"MONTHLY\", 'nonTradingDayFillMethod':'NIL_VALUE'})\n",
    "        last_price = last_price_df['last_price'].iloc[0] \n",
    "\n",
    "        # Append the data to the list\n",
    "        data.append([currency, last_price])\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving data for {ticker}: {e}\")\n",
    "\n",
    "# Create the DataFrame from the collected data\n",
    "inflation  = pd.DataFrame(data, columns=['Currency', 'CPI YOY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_cpi_dict(final_cpi_data, all_currencies):\n",
    "    cpi_dict = {}\n",
    "    final_cpi_data['Date'] = pd.to_datetime(final_cpi_data['Date'])\n",
    "    for date in final_cpi_data['Date'].unique():\n",
    "        date_str = date.strftime('%Y-%m-%d')  # Format date as string for consistency\n",
    "        date_data = final_cpi_data[final_cpi_data['Date'] == date].copy()\n",
    "\n",
    "        # Create the correctly formatted DataFrame\n",
    "        temp_df = pd.DataFrame(index=all_currencies, columns=['CPI']) # Use all_currencies as index\n",
    "        for currency in all_currencies:  \n",
    "            if (date_data['Currency'] == currency).any():  # Check if the currency exists for this date\n",
    "                temp_df.loc[currency, 'CPI'] = date_data.loc[date_data['Currency'] == currency, 'CPI'].iloc[0]\n",
    "            else:\n",
    "                temp_df.loc[currency, 'CPI'] = np.nan  # Handle missing currencies\n",
    "        temp_df = temp_df.reset_index().rename(columns={'index':'Currency'}) \n",
    "        cpi_dict[date_str] = temp_df  # Store with date string as key\n",
    "\n",
    "    return cpi_dict\n",
    "all_currencies = [\"BRL\",\"CLP\",\"CNY\",\"COP\",\"CZK\",\"HUF\",\"IDR\",\"MYR\",\"MXN\",\"PEN\",\"PHP\",\"PLN\",\"RON\",\"RUB\",\"ZAR\",\"THB\",\"TRY\",\"INR\",\"SGD\",\"TWD\",\"KRW\",\"UAH\",\"EGP\",\"EUR\",\"JPY\",\"USD\",\"GBP\",\"CAD\",\"ARS\",\"CHF\"]\n",
    "cpi_dict = create_cpi_dict(final_cpi_data, all_currencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xbbg import blp\n",
    "\n",
    "def get_reer_data(date, securities, currencies):\n",
    "    begin = ((date - pd.DateOffset(months=150)).replace(day=1)).strftime('%Y-%m-%d')\n",
    "    end = date.strftime('%Y-%m-%d')\n",
    "\n",
    "    REER_query = blp.bdh(\n",
    "        securities,\n",
    "        [\"PX_LAST\"],\n",
    "        start_date=begin,\n",
    "        end_date=end\n",
    "    )\n",
    "\n",
    "    REER_query.columns = REER_query.columns.get_level_values(0)  # Flatten MultiIndex\n",
    "\n",
    "    ticker_to_currency = dict(zip(securities, currencies))\n",
    "    REER_query = REER_query.rename(columns=ticker_to_currency)  #Rename currency tickers\n",
    "\n",
    "    REER_query = REER_query.stack().reset_index() #Stacking to multiindex\n",
    "    REER_query.columns = ['date', 'Currency', 'PX_LAST'] #Renaming accordingly because of stack's naming convention for the tickers columns\n",
    "   \n",
    "    REER_query = REER_query.pivot(index='date', columns='Currency', values='PX_LAST') #pivoting correctly after having stacked\n",
    "\n",
    "    return REER_query\n",
    "\n",
    "\n",
    "# Example Usage (replace with your lists and date)\n",
    "securities = [\"BISBBRR Index\",\"BISBCLR Index\",\"BISBCNR Index\",\"BISBCOP Index\",\"BISBCZR Index\",\"BISBHUR Index\",\"BISBIDR Index\",\"BISBMYR Index\",\"BISBMXR Index\",\"BISBPER Index\",\"BISBPHR Index\",\"BISBPLR Index\",\"BISBROR Index\",\"BISBRUR Index\",\"BISBZAR Index\",\"BISBTHR Index\",\"BISBTRR Index\",\"BISBINR Index\",\"BISBSGR Index\",\"BISBTWR Index\",\"BISBKRR Index\"]\n",
    "currencies = [\"BRL\", \"CLP\", \"CNY\", \"COP\", \"CZK\", \"HUF\", \"IDR\", \"MYR\", \"MXN\", \"PEN\", \"PHP\", \"PLN\", \"RON\", \"RUB\", \"ZAR\", \"THB\", \"TRY\", \"INR\", \"SGD\", \"TWD\", \"KRW\"]\n",
    "date = pd.to_datetime('2024-11-26')\n",
    "\n",
    "reer_data = get_reer_data(date, securities, currencies)\n",
    "reer_data = reer_data.reset_index(drop=False)  # Remove current index if date isn't a column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_5yr_avg_reer(reer_data, currencies):\n",
    "    reer_data['date'] = pd.to_datetime(reer_data['date'])\n",
    "    reer_data = reer_data.sort_values('date')\n",
    "    reer_data = reer_data.set_index('date')\n",
    "\n",
    "    for currency in currencies:\n",
    "        reer_data[f'{currency}_5yr_rolling'] = np.nan  # Initialize\n",
    "\n",
    "        for i in range(len(reer_data)):\n",
    "            current_date = reer_data.index[i]\n",
    "            five_years_ago = current_date - pd.DateOffset(months=61) #Modified to start 61 months ago\n",
    "            past_month = current_date - pd.DateOffset(months=1) #Defined past month\n",
    "            past_data = reer_data.loc[five_years_ago:past_month, currency].dropna() #Selects data between 61 months ago and last month (excluded), removing NaNs\n",
    "\n",
    "            if len(past_data) >= 60:\n",
    "                reer_data.loc[current_date, f'{currency}_5yr_rolling'] = past_data.mean()\n",
    "\n",
    "    return reer_data.reset_index(drop=False)\n",
    "\n",
    "securities = [\"BISBBRR Index\", \"BISBCLR Index\", \"BISBCNR Index\",  \"BISBCOP Index\",\"BISBCZR Index\", \"BISBHUR Index\", \"BISBIDR Index\", \"BISBMYR Index\", \"BISBMXR Index\",  \"BISBPER Index\",\"BISBPHR Index\",  \"BISBPLR Index\",  \"BISBROR Index\",  \"BISBRUR Index\",\"BISBZAR Index\", \"BISBTHR Index\",  \"BISBTRR Index\", \"BISBINR Index\", \"BISBSGR Index\", \"BISBTWR Index\", \"BISBKRR Index\"] #Use actual tickers\n",
    "currencies = ['BRL', 'CLP', 'CNY', 'COP', 'CZK', 'HUF', 'IDR','INR','KRW','MYR','MXN','PEN','PHP','PLN','RON','RUB','SGD','THB','TRY','TWD','ZAR']# Actual list matching ticker elements without the date column.\n",
    "date = pd.to_datetime('2024-09-30') # Your target date\n",
    "reer_data = calculate_5yr_avg_reer(reer_data, currencies)\n",
    "\n",
    "# Convert the 'date' column to datetime objects if it's not already\n",
    "reer_data['date'] = pd.to_datetime(reer_data['date'])\n",
    "\n",
    "# Format the dates as 'YYYY-MM-DD' strings\n",
    "reer_data['date'] = reer_data['date'].dt.strftime('%Y-%m-%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "reer_dict = {}\n",
    "\n",
    "\n",
    "for date in reer_data['date'].unique():\n",
    "    date_data = reer_data[reer_data['date'] == date].copy()\n",
    "    date_data = date_data.drop(columns='date')\n",
    "\n",
    "    temp_df = pd.DataFrame(index=currencies, columns=['REER', 'REER_5Y_avg'])\n",
    "\n",
    "    for currency in currencies:\n",
    "        reer_col = currency\n",
    "        rolling_col = currency + \"_5yr_rolling\"\n",
    "\n",
    "        if rolling_col in reer_data.columns:\n",
    "            temp_df.loc[currency, 'REER'] = date_data[reer_col].iloc[0]\n",
    "            temp_df.loc[currency, 'REER_5Y_avg'] = date_data[rolling_col].iloc[0]\n",
    "        else:\n",
    "            temp_df.loc[currency, 'REER'] = date_data[reer_col].iloc[0]\n",
    "            temp_df.loc[currency, 'REER_5Y_avg'] = np.nan\n",
    "\n",
    "    # Add Currency as a column before resetting indexFTB_3\n",
    "    \n",
    "    temp_df = temp_df.reset_index().rename(columns={'index': 'Currency'}) \n",
    "    reer_dict[date] = temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trading weights is an independent part \n",
    "\n",
    "from blp import blp \n",
    "weights = {'BRL': { 'EUR':19.8326891433532, 'CNY': 19.31908920559, 'USD': 18.9827326781795, 'ARS': 9.04088735496284, 'KRW': 4.00326543003275}, \n",
    "         'CLP': { 'CNY':32.4903579496702, 'USD': 15.7403934634422, 'EUR': 15.7221929477127, 'BRL': 5.30539472417201, 'KRW': 4.85057074105527},\n",
    "         'CNY': { 'USD':19.6807605546305, 'EUR': 18.034148790699, 'JPY': 11.9337085872547, 'KRW': 8.77690798092872, 'TWD': 5.94072168056887},\n",
    "         'COP': { 'CNY':23.7228279745679, 'USD': 22.3958427765579, 'EUR': 15.0561850379673, 'MXN': 9.47818212291651, 'BRL': 5.79804369588218},\n",
    "         'CZK': { 'EUR':53.7357432005846, 'CNY': 9.32263987744015, 'PLN': 6.48343861856898, 'USD': 4.57420251197199, 'GBP': 4.46219657045916},\n",
    "         'HUF': { 'EUR':51.4462139331452, 'CNY': 8.5469463341168, 'USD': 5.49254146539307, 'PLN': 4.89862553996062, 'CZK': 4.01613062014827},\n",
    "         'IDR': { 'CNY':23.2668581166172, 'JPY': 12.4015844911697, 'EUR': 10.7498551165224, 'SGD': 9.67219382822659, 'USD': 9.16342505380052},\n",
    "         'MYR': { 'CNY':23.7465947578572, 'USD': 13.0350647634701, 'EUR': 11.4157257777885, 'JPY': 9.45471669844536, 'SGD': 8.43320915760798},\n",
    "         'MXN': { 'USD':53.7852968728671, 'CNY': 15.3570822350254, 'EUR': 8.85721047352065, 'JPY': 3.68473624173183, 'CAD': 3.65211347020733},\n",
    "         'PEN': { 'CNY':27.8771478535743, 'USD': 18.0329542150098, 'EUR': 12.372696604013, 'BRL': 6.19816245225753, 'MXN': 5.04137616220383},\n",
    "         'PHP': { 'CNY':20.860353198127, 'JPY': 15.316588250294, 'USD': 12.1367056047445, 'EUR': 10.5339870265713, 'KRW': 6.90886495923643},\n",
    "         'PLN': { 'EUR':51.2744348107249, 'CNY': 11.8457719861224, 'GBP': 4.84680781974116, 'USD': 4.56041842863057, 'CZK': 3.76300172956997},\n",
    "         'RON': { 'EUR':53.163229044445, 'CNY': 7.52963234306008, 'HUF': 4.58419055313407, 'PLN': 4.30552373422745, 'GBP': 4.06001591246192},\n",
    "         'RUB': { 'EUR':36.5454149814027, 'CNY': 21.6181286031918, 'USD': 7.13934430006148, 'JPY': 4.60563918801572, 'KRW': 3.55071673784711},\n",
    "         'ZAR': { 'EUR':28.0706716305097, 'CNY': 21.9557456326697, 'USD': 11.4296519508831, 'JPY': 6.34943112088636, 'GBP': 4.6456625826538},\n",
    "         'THB': { 'CNY':23.5940786001256, 'JPY': 15.7028546336318, 'USD': 10.731028129059, 'EUR': 10.454098946585, 'MYR': 4.48452665287658},\n",
    "         'TRY': { 'EUR':40.3579265739337, 'CNY': 14.6056217841577, 'USD': 6.35823987754735, 'GBP': 5.14480031288076, 'KRW': 3.5563885504494},\n",
    "         'INR': { 'CNY':23.0813819215815, 'EUR': 18.4229102981809, 'USD': 13.9630590579442, 'KRW': 4.68345461835726, 'JPY': 4.55859195195944},\n",
    "         'SGD': { 'CNY':22.4672690983772, 'EUR': 11.4224275576858, 'USD': 11.3383351154703, 'JPY': 7.95992633793645, 'MYR': 7.31117597215136},\n",
    "         'TWD': { 'CNY':34.561520327848, 'JPY': 13.5244959365383, 'USD': 12.9747862420664, 'EUR': 10.1631302332482, 'KRW': 5.92150265900429},\n",
    "         'KRW': { 'CNY':33.2674159298525, 'USD': 13.9679646593416, 'EUR': 12.7550195378573, 'JPY': 10.8782446505293, 'TWD': 4.03210645129297},\n",
    "         'EUR': { 'CNY':18.3714673852213, 'USD': 14.5632639529848, 'GBP': 10.440394166651, 'CHF': 5.54635594069113, 'PLN': 5.50799014172826},\n",
    "         'JPY': { 'CNY':31.8896059983949, 'USD': 16.4932499426125, 'EUR': 12.6796695252115, 'KRW': 5.95597200870829, 'TWD': 4.60760731009828}\n",
    "}\n",
    "\n",
    "df = pd.DataFrame.from_dict(weights, orient='index').fillna(0)\n",
    "df['total_weight'] = df.apply(sum, axis =1)\n",
    "df.reset_index(inplace=True)\n",
    "df.rename(columns={'index':'Currency'}, inplace=True)\n",
    "trading_weights = pd.melt(df,id_vars=[\"Currency\", 'total_weight'], var_name=\"Trading partner\", value_name=\"weight\")\n",
    "trading_weights = trading_weights[trading_weights['weight'] != 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## DATA PRICES \n",
    "from xbbg import blp \n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# Define the list of Bloomberg tickers\n",
    "tickers = [\"BRL BGN Curncy\", \"CLP BGN Curncy\", \"CNY CMPN Curncy\", \"COP REGN Curncy\",\n",
    "           \"CZK BGN Curncy\", \"HUF BGN Curncy\", \"IDR CMPN Curncy\", \"MYR CMPN Curncy\",\n",
    "           \"MXN BGN Curncy\", \"PEN BGN Curncy\", \"PHP CMPN Curncy\", \"PLN BGN Curncy\",\n",
    "           \"RON BGN Curncy\", \"RUB BGN Curncy\", \"ZAR BGN Curncy\", \"THB BGN Curncy\",\n",
    "           \"TRY BGN Curncy\", \"INR CMPN Curncy\", \"SGD BGN Curncy\", \"TWD BGN Curncy\",\n",
    "           \"KRW CMPN Curncy\"]\n",
    "\n",
    "# Extract currency codes from tickers\n",
    "currencies = [ticker[:3] for ticker in tickers]\n",
    "\n",
    "# Get historical data for the past 5 years\n",
    "end_date = pd.Timestamp.today()\n",
    "start_date = end_date - relativedelta(years=5)\n",
    "\n",
    "data_prices = blp.bdh(tickers, 'PX_LAST', '20150101', end_date)\n",
    "data_prices.columns = currencies\n",
    "data_prices\n",
    "\n",
    "\n",
    "all_business_dates = pd.to_datetime(data_prices.index)\n",
    "all_business_dates_str = [date.strftime('%Y-%m-%d') for date in all_business_dates]\n",
    "\n",
    "all_business_dates_str[-50:]\n",
    "all_business_dates = pd.to_datetime(data_prices.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRL</th>\n",
       "      <th>CLP</th>\n",
       "      <th>CNY</th>\n",
       "      <th>COP</th>\n",
       "      <th>CZK</th>\n",
       "      <th>HUF</th>\n",
       "      <th>IDR</th>\n",
       "      <th>MYR</th>\n",
       "      <th>MXN</th>\n",
       "      <th>PEN</th>\n",
       "      <th>...</th>\n",
       "      <th>PLN</th>\n",
       "      <th>RON</th>\n",
       "      <th>RUB</th>\n",
       "      <th>ZAR</th>\n",
       "      <th>THB</th>\n",
       "      <th>TRY</th>\n",
       "      <th>INR</th>\n",
       "      <th>SGD</th>\n",
       "      <th>TWD</th>\n",
       "      <th>KRW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>606.600</td>\n",
       "      <td>6.2077</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.88595</td>\n",
       "      <td>261.460</td>\n",
       "      <td>12405.0</td>\n",
       "      <td>3.4993</td>\n",
       "      <td>14.74675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.54160</td>\n",
       "      <td>3.70435</td>\n",
       "      <td>57.80176</td>\n",
       "      <td>11.54804</td>\n",
       "      <td>32.9500</td>\n",
       "      <td>2.33138</td>\n",
       "      <td>63.22501</td>\n",
       "      <td>1.32351</td>\n",
       "      <td>31.6350</td>\n",
       "      <td>1093.245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>2.69420</td>\n",
       "      <td>613.413</td>\n",
       "      <td>6.2063</td>\n",
       "      <td>2374.000</td>\n",
       "      <td>23.05705</td>\n",
       "      <td>264.810</td>\n",
       "      <td>12526.0</td>\n",
       "      <td>3.5293</td>\n",
       "      <td>14.83840</td>\n",
       "      <td>2.97520</td>\n",
       "      <td>...</td>\n",
       "      <td>3.58623</td>\n",
       "      <td>3.73630</td>\n",
       "      <td>58.75000</td>\n",
       "      <td>11.68320</td>\n",
       "      <td>32.9700</td>\n",
       "      <td>2.34495</td>\n",
       "      <td>63.23451</td>\n",
       "      <td>1.33129</td>\n",
       "      <td>31.7730</td>\n",
       "      <td>1107.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>2.70595</td>\n",
       "      <td>617.000</td>\n",
       "      <td>6.2219</td>\n",
       "      <td>2429.600</td>\n",
       "      <td>23.20675</td>\n",
       "      <td>266.393</td>\n",
       "      <td>12621.8</td>\n",
       "      <td>3.5570</td>\n",
       "      <td>14.94527</td>\n",
       "      <td>2.98950</td>\n",
       "      <td>...</td>\n",
       "      <td>3.59485</td>\n",
       "      <td>3.76720</td>\n",
       "      <td>61.61680</td>\n",
       "      <td>11.70768</td>\n",
       "      <td>32.9700</td>\n",
       "      <td>2.33056</td>\n",
       "      <td>63.48601</td>\n",
       "      <td>1.33533</td>\n",
       "      <td>31.9765</td>\n",
       "      <td>1109.645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>2.70075</td>\n",
       "      <td>616.625</td>\n",
       "      <td>6.2154</td>\n",
       "      <td>2450.170</td>\n",
       "      <td>23.26683</td>\n",
       "      <td>268.883</td>\n",
       "      <td>12652.4</td>\n",
       "      <td>3.5637</td>\n",
       "      <td>14.89475</td>\n",
       "      <td>2.98950</td>\n",
       "      <td>...</td>\n",
       "      <td>3.63188</td>\n",
       "      <td>3.78303</td>\n",
       "      <td>63.09165</td>\n",
       "      <td>11.71350</td>\n",
       "      <td>32.8600</td>\n",
       "      <td>2.32251</td>\n",
       "      <td>63.46051</td>\n",
       "      <td>1.33330</td>\n",
       "      <td>31.9900</td>\n",
       "      <td>1099.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-07</th>\n",
       "      <td>2.68288</td>\n",
       "      <td>615.200</td>\n",
       "      <td>6.2116</td>\n",
       "      <td>2427.925</td>\n",
       "      <td>23.53110</td>\n",
       "      <td>268.470</td>\n",
       "      <td>12680.0</td>\n",
       "      <td>3.5709</td>\n",
       "      <td>14.71500</td>\n",
       "      <td>2.99050</td>\n",
       "      <td>...</td>\n",
       "      <td>3.62664</td>\n",
       "      <td>3.79890</td>\n",
       "      <td>62.90001</td>\n",
       "      <td>11.68082</td>\n",
       "      <td>32.8700</td>\n",
       "      <td>2.31947</td>\n",
       "      <td>63.15501</td>\n",
       "      <td>1.33972</td>\n",
       "      <td>31.9790</td>\n",
       "      <td>1098.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-02</th>\n",
       "      <td>6.06810</td>\n",
       "      <td>978.205</td>\n",
       "      <td>7.2740</td>\n",
       "      <td>4460.080</td>\n",
       "      <td>24.04051</td>\n",
       "      <td>394.830</td>\n",
       "      <td>15896.5</td>\n",
       "      <td>4.4600</td>\n",
       "      <td>20.39821</td>\n",
       "      <td>3.75550</td>\n",
       "      <td>...</td>\n",
       "      <td>4.08120</td>\n",
       "      <td>4.74038</td>\n",
       "      <td>106.50000</td>\n",
       "      <td>18.13337</td>\n",
       "      <td>34.5004</td>\n",
       "      <td>34.71974</td>\n",
       "      <td>84.72506</td>\n",
       "      <td>1.34488</td>\n",
       "      <td>32.6310</td>\n",
       "      <td>1405.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-03</th>\n",
       "      <td>6.05055</td>\n",
       "      <td>972.250</td>\n",
       "      <td>7.2882</td>\n",
       "      <td>4440.813</td>\n",
       "      <td>23.94380</td>\n",
       "      <td>394.375</td>\n",
       "      <td>15953.0</td>\n",
       "      <td>4.4700</td>\n",
       "      <td>20.31532</td>\n",
       "      <td>3.73760</td>\n",
       "      <td>...</td>\n",
       "      <td>4.09015</td>\n",
       "      <td>4.73585</td>\n",
       "      <td>105.00000</td>\n",
       "      <td>18.11590</td>\n",
       "      <td>34.3474</td>\n",
       "      <td>34.73285</td>\n",
       "      <td>84.68241</td>\n",
       "      <td>1.34485</td>\n",
       "      <td>32.5496</td>\n",
       "      <td>1415.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-04</th>\n",
       "      <td>6.03979</td>\n",
       "      <td>974.955</td>\n",
       "      <td>7.2652</td>\n",
       "      <td>4415.730</td>\n",
       "      <td>23.94567</td>\n",
       "      <td>393.346</td>\n",
       "      <td>15897.0</td>\n",
       "      <td>4.4550</td>\n",
       "      <td>20.29653</td>\n",
       "      <td>3.73850</td>\n",
       "      <td>...</td>\n",
       "      <td>4.07220</td>\n",
       "      <td>4.73497</td>\n",
       "      <td>105.00000</td>\n",
       "      <td>18.16400</td>\n",
       "      <td>34.2738</td>\n",
       "      <td>34.74456</td>\n",
       "      <td>84.70776</td>\n",
       "      <td>1.34387</td>\n",
       "      <td>32.4305</td>\n",
       "      <td>1413.465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-05</th>\n",
       "      <td>6.00696</td>\n",
       "      <td>970.250</td>\n",
       "      <td>7.2597</td>\n",
       "      <td>4415.268</td>\n",
       "      <td>23.69062</td>\n",
       "      <td>390.045</td>\n",
       "      <td>15846.0</td>\n",
       "      <td>4.4280</td>\n",
       "      <td>20.19555</td>\n",
       "      <td>3.72668</td>\n",
       "      <td>...</td>\n",
       "      <td>4.03267</td>\n",
       "      <td>4.70388</td>\n",
       "      <td>100.75437</td>\n",
       "      <td>18.01566</td>\n",
       "      <td>34.1360</td>\n",
       "      <td>34.71364</td>\n",
       "      <td>84.67166</td>\n",
       "      <td>1.33893</td>\n",
       "      <td>32.4020</td>\n",
       "      <td>1415.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-06</th>\n",
       "      <td>6.08635</td>\n",
       "      <td>975.669</td>\n",
       "      <td>7.2715</td>\n",
       "      <td>4412.985</td>\n",
       "      <td>23.77990</td>\n",
       "      <td>392.584</td>\n",
       "      <td>15850.0</td>\n",
       "      <td>4.4220</td>\n",
       "      <td>20.27900</td>\n",
       "      <td>3.72386</td>\n",
       "      <td>...</td>\n",
       "      <td>4.04192</td>\n",
       "      <td>4.70577</td>\n",
       "      <td>100.54915</td>\n",
       "      <td>18.02565</td>\n",
       "      <td>34.0519</td>\n",
       "      <td>34.79740</td>\n",
       "      <td>84.70451</td>\n",
       "      <td>1.34189</td>\n",
       "      <td>32.3850</td>\n",
       "      <td>1423.305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2592 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                BRL      CLP     CNY       COP       CZK      HUF      IDR  \\\n",
       "2015-01-01      NaN  606.600  6.2077       NaN  22.88595  261.460  12405.0   \n",
       "2015-01-02  2.69420  613.413  6.2063  2374.000  23.05705  264.810  12526.0   \n",
       "2015-01-05  2.70595  617.000  6.2219  2429.600  23.20675  266.393  12621.8   \n",
       "2015-01-06  2.70075  616.625  6.2154  2450.170  23.26683  268.883  12652.4   \n",
       "2015-01-07  2.68288  615.200  6.2116  2427.925  23.53110  268.470  12680.0   \n",
       "...             ...      ...     ...       ...       ...      ...      ...   \n",
       "2024-12-02  6.06810  978.205  7.2740  4460.080  24.04051  394.830  15896.5   \n",
       "2024-12-03  6.05055  972.250  7.2882  4440.813  23.94380  394.375  15953.0   \n",
       "2024-12-04  6.03979  974.955  7.2652  4415.730  23.94567  393.346  15897.0   \n",
       "2024-12-05  6.00696  970.250  7.2597  4415.268  23.69062  390.045  15846.0   \n",
       "2024-12-06  6.08635  975.669  7.2715  4412.985  23.77990  392.584  15850.0   \n",
       "\n",
       "               MYR       MXN      PEN  ...      PLN      RON        RUB  \\\n",
       "2015-01-01  3.4993  14.74675      NaN  ...  3.54160  3.70435   57.80176   \n",
       "2015-01-02  3.5293  14.83840  2.97520  ...  3.58623  3.73630   58.75000   \n",
       "2015-01-05  3.5570  14.94527  2.98950  ...  3.59485  3.76720   61.61680   \n",
       "2015-01-06  3.5637  14.89475  2.98950  ...  3.63188  3.78303   63.09165   \n",
       "2015-01-07  3.5709  14.71500  2.99050  ...  3.62664  3.79890   62.90001   \n",
       "...            ...       ...      ...  ...      ...      ...        ...   \n",
       "2024-12-02  4.4600  20.39821  3.75550  ...  4.08120  4.74038  106.50000   \n",
       "2024-12-03  4.4700  20.31532  3.73760  ...  4.09015  4.73585  105.00000   \n",
       "2024-12-04  4.4550  20.29653  3.73850  ...  4.07220  4.73497  105.00000   \n",
       "2024-12-05  4.4280  20.19555  3.72668  ...  4.03267  4.70388  100.75437   \n",
       "2024-12-06  4.4220  20.27900  3.72386  ...  4.04192  4.70577  100.54915   \n",
       "\n",
       "                 ZAR      THB       TRY       INR      SGD      TWD       KRW  \n",
       "2015-01-01  11.54804  32.9500   2.33138  63.22501  1.32351  31.6350  1093.245  \n",
       "2015-01-02  11.68320  32.9700   2.34495  63.23451  1.33129  31.7730  1107.050  \n",
       "2015-01-05  11.70768  32.9700   2.33056  63.48601  1.33533  31.9765  1109.645  \n",
       "2015-01-06  11.71350  32.8600   2.32251  63.46051  1.33330  31.9900  1099.250  \n",
       "2015-01-07  11.68082  32.8700   2.31947  63.15501  1.33972  31.9790  1098.740  \n",
       "...              ...      ...       ...       ...      ...      ...       ...  \n",
       "2024-12-02  18.13337  34.5004  34.71974  84.72506  1.34488  32.6310  1405.425  \n",
       "2024-12-03  18.11590  34.3474  34.73285  84.68241  1.34485  32.5496  1415.500  \n",
       "2024-12-04  18.16400  34.2738  34.74456  84.70776  1.34387  32.4305  1413.465  \n",
       "2024-12-05  18.01566  34.1360  34.71364  84.67166  1.33893  32.4020  1415.240  \n",
       "2024-12-06  18.02565  34.0519  34.79740  84.70451  1.34189  32.3850  1423.305  \n",
       "\n",
       "[2592 rows x 21 columns]"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xbbg import blp \n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# Define the list of Bloomberg tickers\n",
    "tickers = [\"BRL BGN Curncy\", \"CLP BGN Curncy\", \"CNY CMPN Curncy\", \"COP REGN Curncy\",\n",
    "           \"CZK BGN Curncy\", \"HUF BGN Curncy\", \"IDR CMPN Curncy\", \"MYR CMPN Curncy\",\n",
    "           \"MXN BGN Curncy\", \"PEN BGN Curncy\", \"PHP CMPN Curncy\", \"PLN BGN Curncy\",\n",
    "           \"RON BGN Curncy\", \"RUB BGN Curncy\", \"ZAR BGN Curncy\", \"THB BGN Curncy\",\n",
    "           \"TRY BGN Curncy\", \"INR CMPN Curncy\", \"SGD BGN Curncy\", \"TWD BGN Curncy\",\n",
    "           \"KRW CMPN Curncy\"]\n",
    "\n",
    "# Extract currency codes from tickers\n",
    "currencies = [ticker[:3] for ticker in tickers]\n",
    "\n",
    "# Get historical data for the past 5 years\n",
    "end_date = pd.Timestamp.today()\n",
    "start_date = end_date - relativedelta(years=5)\n",
    "\n",
    "data_prices = blp.bdh(tickers, 'PX_MID', '20150101', end_date)\n",
    "data_prices.columns = currencies\n",
    "data_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_reer_dict(reer_dict, all_business_dates_str):\n",
    "    \"\"\"Forward fills data within each month in the reer_dict.\n",
    "\n",
    "    Preserves all existing keys in reer_dict. Processes dates from 2024 onwards.\n",
    "    GUARANTEES no key removal.\n",
    "    \"\"\"\n",
    "    reer_dict_completed = reer_dict.copy()\n",
    "    all_business_dates = pd.to_datetime(all_business_dates_str).sort_values()\n",
    "    all_business_dates_from_2024 = all_business_dates[all_business_dates >= pd.to_datetime('2024-01-01')]\n",
    "\n",
    "    # Keep track of the latest available date *from any point in the data*\n",
    "    last_available_date_overall = None\n",
    "    for date_str in reer_dict:  # Pre-populate with existing dates from reer_dict if before 2024\n",
    "        dt = pd.to_datetime(date_str)\n",
    "        if last_available_date_overall is None or dt > last_available_date_overall:\n",
    "            last_available_date_overall = dt\n",
    "\n",
    "\n",
    "    for date in all_business_dates_from_2024:\n",
    "        date_str = date.strftime('%Y-%m-%d')\n",
    "\n",
    "        if date_str not in reer_dict_completed:\n",
    "\n",
    "            previous_date = date - pd.DateOffset(days=1)\n",
    "            previous_date_str = previous_date.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "\n",
    "            while previous_date_str not in reer_dict_completed and previous_date >= all_business_dates[0]: # iterate from current date to earliest available date\n",
    "                previous_date -= pd.DateOffset(days=1)\n",
    "                previous_date_str = previous_date.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "            if previous_date_str in reer_dict_completed:\n",
    "                reer_dict_completed[date_str] = reer_dict_completed[previous_date_str].copy()\n",
    "\n",
    "            # If no previous date exists in reer_dict_completed from 2024 onwards, check overall last_available_date_overall\n",
    "            elif last_available_date_overall is not None:\n",
    "\n",
    "                reer_dict_completed[date_str] = reer_dict[last_available_date_overall.strftime('%Y-%m-%d')].copy() # Use overall latest available date\n",
    "\n",
    "\n",
    "\n",
    "            else:\n",
    "                reer_dict_completed[date_str] = pd.DataFrame() # or preferred handling\n",
    "\n",
    "\n",
    "\n",
    "        # Update last_available_date_overall AFTER checking and potentially filling a missing date.\n",
    "        if date_str in reer_dict_completed:\n",
    "            last_available_date_overall = date\n",
    "\n",
    "\n",
    "\n",
    "    return reer_dict_completed\n",
    "reer_dict2 = complete_reer_dict(reer_dict, all_business_dates_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def complete_cpi_dict(cpi_dict, all_business_dates_str):\n",
    "    \"\"\"Completes the cpi_dict by forward-filling missing dates with the last available data.\n",
    "\n",
    "    Preserves all existing keys in cpi_dict.\n",
    "    \"\"\"\n",
    "    cpi_dict_completed = cpi_dict.copy()\n",
    "    all_business_dates = pd.to_datetime(all_business_dates_str).sort_values()\n",
    "\n",
    "    last_available_date_str = None  # Keep track of the last date with available data\n",
    "    last_available_value = None\n",
    "\n",
    "    for date in all_business_dates:  # Iterate through all business dates\n",
    "        date_str = date.strftime('%Y-%m-%d')\n",
    "\n",
    "        if date_str in cpi_dict_completed: #Update the values for existing dates\n",
    "            last_available_date_str = date_str\n",
    "            last_available_value = cpi_dict_completed[date_str]\n",
    "        elif last_available_value is not None : #If it is a missing date, fill with last available value\n",
    "            cpi_dict_completed[date_str] = last_available_value\n",
    "\n",
    "    return cpi_dict_completed\n",
    "\n",
    "cpi_dict_2 = complete_cpi_dict(cpi_dict, all_business_dates_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpi_dict_2 = complete_reer_dict(cpi_dict, all_business_dates_str)\n",
    "#cpi_dict = cpi_dict_2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reer_dict2 and cpi_dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for MYRUSD Curncy: 0\n",
      "Error retrieving data for TWDUSD Curncy: 0\n"
     ]
    }
   ],
   "source": [
    "LAST_UPDATE_query = '20241031' # enter the first date from which you construct the REER \n",
    "def get_adjusted_spot(row, date_current):  # Changed df to row\n",
    "    \"\"\"Calculates the adjusted spot.\"\"\"\n",
    "    currency = row['Currency']  # Access individual values, not Series\n",
    "    trading_partner = row['Trading partner'] # Access individual values, not Series\n",
    "    weight = row['weight']\n",
    "    total_weight = row['total_weight']\n",
    "\n",
    "    security_ticker = f\"{currency}{trading_partner} Curncy\"  # Correct ticker format\n",
    "\n",
    "\n",
    "    try:  # Important: Handle potential Bloomberg errors!\n",
    "        spot_tday = bquery.bdh([security_ticker], [\"PX_LAST\"], start_date=date_current, end_date=date_current, options={\"adjustmentSplit\": True}).loc[0, 'PX_LAST']\n",
    "        spot_last = bquery.bdh([security_ticker], [\"PX_LAST\"], start_date=LAST_UPDATE_query, end_date=LAST_UPDATE_query, options={\"adjustmentSplit\": True}).loc[0, 'PX_LAST']\n",
    "\n",
    "\n",
    "        return ((spot_tday / spot_last) - 1) * weight / total_weight\n",
    "\n",
    "    except Exception as e:  # Handle any Bloomberg API or data errors\n",
    "        print(f\"Error retrieving data for {security_ticker}: {e}\")\n",
    "        return np.nan  # Return NaN for missing or incorrect data\n",
    "\n",
    "# date_current is today \n",
    "date_current = today.strftime('%Y%m%d')\n",
    "trading_weights['spot_adj'] = trading_weights.apply(get_adjusted_spot, date_current='20241126', axis=1) #date as string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blp import blp \n",
    "def calculate_reer_discount(reer_dict2, trading_weights, cpi_dict_2, all_business_dates_str ):\n",
    "    start_date_str = \"2024-11-18\"\n",
    "\n",
    "# Create a filtered list of date strings\n",
    "    filtered_dates = [date_str for date_str in all_business_dates_str if pd.to_datetime(date_str) > pd.to_datetime(start_date_str)]\n",
    "\n",
    "\n",
    "    bquery = blp.BlpQuery().start() #Bloomberg query object\n",
    "    for date_str in filtered_dates: #Iterate through all business dates (string format)\n",
    "        \n",
    "        if date_str in reer_dict2:\n",
    "            print(date_str)\n",
    "            #CPI_query = cpi_dict_2[date_str]\n",
    "            #print(CPI_query)\n",
    "            date = pd.to_datetime(date_str)\n",
    "            last_day_of_previous_month = (date - pd.DateOffset(months=1) + pd.tseries.offsets.MonthEnd(0)).strftime('%Y%m%d')\n",
    "            LAST_UPDATE_query = last_day_of_previous_month\n",
    "            print(LAST_UPDATE_query)\n",
    "            endofmonth = ((date- pd.DateOffset(months=1)).replace(day=1) + pd.DateOffset(months=2) - pd.DateOffset(days=1))\n",
    "            today = pd.Timestamp('today')\n",
    "\n",
    "            date_query = date.strftime('%Y%m%d')\n",
    "\n",
    "            # ADJUSTED SPOT (No changes needed, uses date and LAST_UPDATE_query)\n",
    "            trading_weights['spot_adj'] = trading_weights.apply(get_adjusted_spot, date_current=date_query, axis=1)\n",
    "              #Apply  get_adjusted spot with correct date variables\n",
    "\n",
    "            # ADJUSTED INFLATION (Use date_str to access cpi_dict)\n",
    "            try: #Try/except to handle KeyError if a date is missing\n",
    "                # cpi_dict_2 is completed \n",
    "                print(type(date_str))\n",
    "                CPI_query = cpi_dict_2[date_str]\n",
    "            except KeyError:\n",
    "                print(f\"CPI data not found for {date_str}. Skipping REER discount calculation.\")\n",
    "                continue  # Go to the next date\n",
    "\n",
    "\n",
    "            add_ccycpi = pd.merge(trading_weights, CPI_query, on='Currency')\n",
    "            add_ccycpi.rename(columns={'CPI':'CPI_ccy'}, inplace=True)\n",
    "            add_tpcpi = pd.merge(add_ccycpi, CPI_query, left_on='Trading partner', right_on='Currency').drop(['Currency_y'], axis = 1)\n",
    "            add_tpcpi.rename(columns={'Currency_x':'Currency', 'CPI':'CPI_tp'}, inplace=True)\n",
    "            add_tpcpi['infla_adj']=((add_tpcpi['CPI_ccy']-add_tpcpi['CPI_tp'])/100)*(add_tpcpi['weight']/add_tpcpi['total_weight'])\n",
    "            add_tpcpi=add_tpcpi[['Currency','spot_adj','infla_adj']]\n",
    "\n",
    "            # REER DISCOUNT PROXY (No changes, uses today, LAST_UPDATE, endofmonth)\n",
    "            REER_proxy = add_tpcpi.groupby('Currency').sum().reset_index()\n",
    "            REER_proxy['proxy'] = (1 + REER_proxy['infla_adj'])**((today - pd.to_datetime(LAST_UPDATE_query)).days/(endofmonth - pd.to_datetime(LAST_UPDATE_query)).days) * (1+REER_proxy['spot_adj']) #Corrected: Convert LAST_UPDATE_query to datetime\n",
    "                    \n",
    "            reer_dict2[date_str] = pd.merge(reer_dict2[date_str], REER_proxy, on='Currency')\n",
    "            reer_dict2[date_str]['REER_Discount']=(reer_dict2[date_str]['REER']*reer_dict2[date_str]['proxy']/reer_dict2[date_str]['REER_5Y_avg'])-1\n",
    "            reer_dict2[date_str].sort_values(by='Currency', ascending=True, inplace=True)\n",
    "            \n",
    "\n",
    "            # Merge and update reer_dict (use date_str as key)\n",
    "            #reer_dict2[date_str] = pd.merge(reer_dict2[date_str], REER_proxy[['Currency', 'proxy']], on='Currency', how='left')\n",
    "\n",
    "            #reer_dict2[date_str] = reer_dict2[date_str].reset_index().rename(columns={'index':'Currency'})\n",
    "            #reer_dict2[date_str] = reer_dict2[date_str].set_index('Currency')\n",
    "\n",
    "\n",
    "\n",
    "    bquery.stop() #Stop Bloomberg query session\n",
    "    return reer_dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-19\n",
      "20241031\n",
      "Error retrieving data for MYRUSD Curncy: 0\n",
      "Error retrieving data for TWDUSD Curncy: 0\n",
      "<class 'str'>\n",
      "2024-11-20\n",
      "20241031\n",
      "Error retrieving data for INRCNY Curncy: 0\n",
      "Error retrieving data for BRLUSD Curncy: 0\n",
      "Error retrieving data for MYRUSD Curncy: 0\n",
      "Error retrieving data for INRUSD Curncy: 0\n",
      "Error retrieving data for TWDUSD Curncy: 0\n",
      "Error retrieving data for INRKRW Curncy: 0\n",
      "<class 'str'>\n",
      "2024-11-21\n",
      "20241031\n",
      "Error retrieving data for MYRUSD Curncy: 0\n",
      "Error retrieving data for TWDUSD Curncy: 0\n",
      "<class 'str'>\n",
      "2024-11-22\n",
      "20241031\n",
      "Error retrieving data for MYRUSD Curncy: 0\n",
      "Error retrieving data for TWDUSD Curncy: 0\n",
      "<class 'str'>\n",
      "2024-11-25\n",
      "20241031\n",
      "Error retrieving data for MYRUSD Curncy: 0\n",
      "Error retrieving data for TWDUSD Curncy: 0\n",
      "<class 'str'>\n",
      "2024-11-26\n",
      "20241031\n",
      "Error retrieving data for MYRUSD Curncy: 0\n",
      "Error retrieving data for TWDUSD Curncy: 0\n",
      "<class 'str'>\n",
      "2024-11-27\n",
      "20241031\n",
      "Error retrieving data for IDRUSD Curncy: 0\n",
      "Error retrieving data for MYRUSD Curncy: 0\n",
      "Error retrieving data for TWDUSD Curncy: 0\n",
      "<class 'str'>\n",
      "2024-11-28\n",
      "20241031\n",
      "Error retrieving data for MYRUSD Curncy: 0\n",
      "Error retrieving data for TWDUSD Curncy: 0\n",
      "<class 'str'>\n",
      "2024-11-29\n",
      "20241031\n",
      "Error retrieving data for MYRUSD Curncy: 0\n",
      "Error retrieving data for TWDUSD Curncy: 0\n",
      "<class 'str'>\n",
      "2024-12-02\n",
      "20241130\n",
      "Error retrieving data for MYRUSD Curncy: 0\n",
      "Error retrieving data for TWDUSD Curncy: 0\n",
      "<class 'str'>\n",
      "2024-12-03\n",
      "20241130\n",
      "Error retrieving data for MYRUSD Curncy: 0\n",
      "Error retrieving data for TWDUSD Curncy: 0\n",
      "<class 'str'>\n",
      "2024-12-04\n",
      "20241130\n",
      "Error retrieving data for MYRUSD Curncy: 0\n",
      "Error retrieving data for TWDUSD Curncy: 0\n",
      "<class 'str'>\n",
      "2024-12-05\n",
      "20241130\n",
      "Error retrieving data for MYRUSD Curncy: 0\n",
      "Error retrieving data for TWDUSD Curncy: 0\n",
      "<class 'str'>\n",
      "2024-12-06\n",
      "20241130\n",
      "Error retrieving data for MYRUSD Curncy: 0\n",
      "Error retrieving data for TWDUSD Curncy: 0\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "reer_dict_test = reer_dict2.copy()\n",
    "reer_dict_test = calculate_reer_discount(reer_dict_test, trading_weights, cpi_dict_2, all_business_dates_str )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "strt_date = '20241030'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = today.strftime('%Y%m%d')\n",
    "bquery = blp.BlpQuery().start()\n",
    "fpa3m_query = bquery.bdh(\n",
    "        [\"BCN3M BGN Curncy\",\"CHN3M BGN Curncy\",\"CNH3M CMPN Curncy\",\"CLN3M BGN Curncy\",\"CZK3M BGN Curncy\",\"HUF3M BGN Curncy\",\"IHN3M CMPN Curncy\",\"MRN3M CMPN Curncy\",\"MXN3M BGN Curncy\",\"PSN3M BGN Curncy\",\"PPN3M CMPN Curncy\",\"PLN3M BGN Curncy\",\"RON3M BGN Curncy\",\"RUB3M BGN Curncy\",\"ZAR3M BGN Curncy\",\"THB3M BGN Curncy\",\"TRY3M BGN Curncy\",\"IRN3M CMPN Curncy\",\"SGD3M BGN Curncy\",\"NTN3M BGN Curncy\",\"KWN3M CMPN Curncy\"],\n",
    "        [\"PX_MID\"],\n",
    "        start_date=strt_date,\n",
    "    end_date=end_date,\n",
    "    options={\"adjustmentSplit\": True, \"CDR\": \"5D\"} )\n",
    "\n",
    "fpa3m_query['Cntry_code'] = fpa3m_query['security'].str[:3]\n",
    "fpa3m_query.rename(columns={'PX_MID':'FPA3M_MID'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conditions = [\n",
    "    (fpa3m_query['Cntry_code'] == \"BCN\"),\n",
    "    (fpa3m_query['Cntry_code'] == \"CHN\"),\n",
    "    (fpa3m_query['Cntry_code'] == \"CNH\"),\n",
    "    (fpa3m_query['Cntry_code'] == \"CLN\"),\n",
    "    (fpa3m_query['Cntry_code'] == \"CZK\"),\n",
    "    (fpa3m_query['Cntry_code'] == \"HUF\"),\n",
    "    (fpa3m_query['Cntry_code'] == \"IHN\"),\n",
    "    (fpa3m_query['Cntry_code'] == \"MRN\"),\n",
    "    (fpa3m_query['Cntry_code'] == \"MXN\"),\n",
    "    (fpa3m_query['Cntry_code'] == \"PSN\"),\n",
    "    (fpa3m_query['Cntry_code'] == \"PPN\"),\n",
    "    (fpa3m_query['Cntry_code'] == \"PLN\"),\n",
    "    (fpa3m_query['Cntry_code'] == \"RON\"),\n",
    "    (fpa3m_query['Cntry_code'] == \"RUB\"),\n",
    "    (fpa3m_query['Cntry_code'] == \"ZAR\"),\n",
    "    (fpa3m_query['Cntry_code'] == \"THB\"),\n",
    "    (fpa3m_query['Cntry_code'] == \"TRY\"),\n",
    "    (fpa3m_query['Cntry_code'] == \"IRN\"),\n",
    "    (fpa3m_query['Cntry_code'] == \"SGD\"),\n",
    "    (fpa3m_query['Cntry_code'] == \"NTN\"),\n",
    "    (fpa3m_query['Cntry_code'] == \"KWN\")\n",
    "]\n",
    "\n",
    "# Assuming 'currencies' and 'fwd_scale_dict' are defined elsewhere in your code\n",
    "\n",
    "fpa3m_query['Currency'] = np.select(conditions, currencies, default=None)\n",
    "fpa3m_query.sort_values(by='date', ascending=True, inplace=True)\n",
    "fpa3m_query.reset_index(inplace=True, drop=True)  # Add drop=True to avoid old index as a new column\n",
    "fpa3m_query['FWD_SCALE'] = fpa3m_query['Currency'].map(fwd_scale_dict)\n",
    "fpa3m_query['FPA3M_MID'] = fpa3m_query['FPA3M_MID'] / (10**fpa3m_query['FWD_SCALE'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_fpa_dict(fpa_query):\n",
    "    \"\"\"Creates a dictionary of DataFrames with FPA data organized by date.\n",
    "\n",
    "    Args:\n",
    "        fpa_query: Input DataFrame with 'date_x', 'Currency', 'FPA3M_MID', and 'FPA1M_MID' columns.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with dates ('YYYYMMDD') as keys and DataFrames as values.\n",
    "        DataFrames have 'Currency' as index and 'FPA3M_MID', 'FPA1M_MID' as columns.\n",
    "        If a currency is missing for a date, its FPA values will be NaN.\n",
    "    \"\"\"\n",
    "\n",
    "    fpa_dict = {}\n",
    "    all_currencies = sorted(fpa_query['Currency'].unique())  # Get all unique currencies present\n",
    "\n",
    "\n",
    "    for date, date_df in fpa_query.groupby('date'):  # Group by date\n",
    "        date_str = date.strftime('%Y%m%d')\n",
    "\n",
    "        # Create a DataFrame with all currencies as index for this date\n",
    "        fpa_dict[date_str] = pd.DataFrame(index=all_currencies, columns=['FPA3M_MID'])\n",
    "\n",
    "\n",
    "        temp_df = date_df.set_index('Currency')[['FPA3M_MID','date']] # Select only necessary columns\n",
    "\n",
    "        # Update the DataFrame with the values from temp_df\n",
    "        fpa_dict[date_str].update(temp_df)\n",
    "\n",
    "\n",
    "    return fpa_dict\n",
    "\n",
    "fpa_dict = create_fpa_dict(fpa3m_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blp import blp \n",
    "end_date_str = pd.Timestamp(end_date).strftime('%Y%m%d') \n",
    "strt_date = '2018-01-01'\n",
    "currencies = [\"BRL\", \"CLP\", \"CNY\", \"COP\", \"CZK\", \"HUF\", \"IDR\", \"MYR\", \"MXN\", \"PEN\", \"PHP\", \"PLN\", \"RON\", \"RUB\", \"ZAR\", \"THB\", \"TRY\", \"INR\", \"SGD\", \"TWD\", \"KRW\"]\n",
    "\n",
    "bquery = blp.BlpQuery().start()\n",
    "\n",
    "GDP_query = bquery.bdh(\n",
    "        [\"WGDPBRAZ Index\",\"WGDPCHIL Index\",\"WGDPCHIN Index\",\"WGDPCOLO Index\",\"WGDPCZEC Index\",\"WGDPHUNG Index\",\"WGDPINDO Index\",\"WGDPMALY Index\",\"WGDPMEXI Index\",\"WGDPPERU Index\",\"WGDPPHIL Index\",\"WGDPPOLA Index\",\"WGDPROMA Index\",\"WGDPRUSS Index\",\"WGDPSOUT Index\",\"WGDPTHAI Index\",\"WGDPTURK Index\",\"WGDPINDI Index\",\"WGDPSING Index\",\"TAGDPARE Index\",\"WGDPKORE Index\"],\n",
    "        [\"PX_LAST\"],\n",
    "        start_date= '20210101', \n",
    "        end_date= end_date_str, \n",
    "        options={\"adjustmentSplit\": True, \"nonTradingDayFillOption\":\"ALL_CALENDAR_DAYS\", \"periodicitySelection\":\"YEARLY\", 'nonTradingDayFillMethod':'NIL_VALUE'})\n",
    "\n",
    "GDP_query.rename(columns={'PX_LAST':'GDP'}, inplace=True)\n",
    "\n",
    "conditions = [\n",
    "    (GDP_query['security'] == 'WGDPBRAZ Index'),\n",
    "    (GDP_query['security'] == 'WGDPCHIL Index'),\n",
    "    (GDP_query['security'] == 'WGDPCHIN Index'),\n",
    "    (GDP_query['security'] == 'WGDPCOLO Index'),\n",
    "    (GDP_query['security'] == 'WGDPCZEC Index'),\n",
    "    (GDP_query['security'] == 'WGDPHUNG Index'),\n",
    "    (GDP_query['security'] == 'WGDPINDO Index'),\n",
    "    (GDP_query['security'] == 'WGDPMALY Index'),\n",
    "    (GDP_query['security'] == 'WGDPMEXI Index'),\n",
    "    (GDP_query['security'] == 'WGDPPERU Index'),\n",
    "    (GDP_query['security'] == 'WGDPPHIL Index'),\n",
    "    (GDP_query['security'] == 'WGDPPOLA Index'),\n",
    "    (GDP_query['security'] == 'WGDPROMA Index'),\n",
    "    (GDP_query['security'] == 'WGDPRUSS Index'),\n",
    "    (GDP_query['security'] == 'WGDPSOUT Index'),\n",
    "    (GDP_query['security'] == 'WGDPTHAI Index'),\n",
    "    (GDP_query['security'] == 'WGDPTURK Index'),\n",
    "    (GDP_query['security'] == 'WGDPINDI Index'),\n",
    "    (GDP_query['security'] == 'WGDPSING Index'),\n",
    "    (GDP_query['security'] == 'TAGDPARE Index'),\n",
    "    (GDP_query['security'] == 'WGDPKORE Index')\n",
    "]\n",
    "\n",
    "GDP_query['Currency'] = np.select(conditions, currencies, default=None)\n",
    "GDP_query.sort_values(by='Currency', ascending=True, inplace=True)\n",
    "GDP_query.reset_index(inplace=True)\n",
    "GDP_query=GDP_query[['Currency','GDP']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "securities = [\"WGDPBRAZ Index\",\"WGDPCHIL Index\",\"WGDPCHIN Index\",\"WGDPCOLO Index\",\"WGDPCZEC Index\",\"WGDPHUNG Index\",\"WGDPINDO Index\",\"WGDPMALY Index\",\"WGDPMEXI Index\",\"WGDPPERU Index\",\"WGDPPHIL Index\",\"WGDPPOLA Index\",\"WGDPROMA Index\",\"WGDPRUSS Index\",\"WGDPSOUT Index\",\"WGDPTHAI Index\",\"WGDPTURK Index\",\"WGDPINDI Index\",\"WGDPSING Index\",\"TAGDPARE Index\",\"WGDPKORE Index\"]\n",
    "fields = [\"PX_LAST\"]\n",
    "start_date= '20180101'\n",
    "end_date= end_date_str\n",
    "options={\"adjustmentSplit\": True, \"nonTradingDayFillOption\":\"ALL_CALENDAR_DAYS\", \"periodicitySelection\":\"YEARLY\", 'nonTradingDayFillMethod':'NIL_VALUE'}\n",
    "\n",
    "GDP_data = [] # list to store individual dataframes\n",
    "\n",
    "for security in securities:\n",
    "    try:\n",
    "        df = bquery.bdh([security], fields, start_date=start_date, end_date=end_date_str, options=options)\n",
    "\n",
    "        if not df.empty:\n",
    "            df['Currency'] = currencies[securities.index(security)]  # Add currency using index\n",
    "            GDP_data.append(df) # Append DataFrame\n",
    "        else:\n",
    "            print(f\"No data retrieved for {security}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving data for {security}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UT3P5T\\AppData\\Local\\Temp\\1/ipykernel_28404/1478019926.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  GDP_data[date_str] = pd.concat([GDP_data[date_str], pd.DataFrame({'Currency': [currency], 'GDP': [row['GDP']]})], ignore_index=True)\n",
      "C:\\Users\\UT3P5T\\AppData\\Local\\Temp\\1/ipykernel_28404/1478019926.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  GDP_data[date_str] = pd.concat([GDP_data[date_str], pd.DataFrame({'Currency': [currency], 'GDP': [row['GDP']]})], ignore_index=True)\n",
      "C:\\Users\\UT3P5T\\AppData\\Local\\Temp\\1/ipykernel_28404/1478019926.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  GDP_data[date_str] = pd.concat([GDP_data[date_str], pd.DataFrame({'Currency': [currency], 'GDP': [row['GDP']]})], ignore_index=True)\n",
      "C:\\Users\\UT3P5T\\AppData\\Local\\Temp\\1/ipykernel_28404/1478019926.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  GDP_data[date_str] = pd.concat([GDP_data[date_str], pd.DataFrame({'Currency': [currency], 'GDP': [row['GDP']]})], ignore_index=True)\n",
      "C:\\Users\\UT3P5T\\AppData\\Local\\Temp\\1/ipykernel_28404/1478019926.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  GDP_data[date_str] = pd.concat([GDP_data[date_str], pd.DataFrame({'Currency': [currency], 'GDP': [row['GDP']]})], ignore_index=True)\n",
      "C:\\Users\\UT3P5T\\AppData\\Local\\Temp\\1/ipykernel_28404/1478019926.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  GDP_data[date_str] = pd.concat([GDP_data[date_str], pd.DataFrame({'Currency': [currency], 'GDP': [row['GDP']]})], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n"
     ]
    }
   ],
   "source": [
    "GDP_data = {}\n",
    "\n",
    "for security in securities:\n",
    "    try:\n",
    "        df = bquery.bdh([security], fields, start_date=start_date, end_date=end_date_str, options=options)\n",
    "        if not df.empty:\n",
    "            currency = currencies[securities.index(security)]\n",
    "            df.rename(columns={'PX_LAST': 'GDP'}, inplace=True)\n",
    "\n",
    "            for index, row in df.iterrows():\n",
    "                \n",
    "                year = row['date'].year  # Get the year (which is now the index)\n",
    "                print(year)\n",
    "                date_str = str(year) + '-12-31'\n",
    "  # Create date string YYYY1231 for end of year\n",
    "\n",
    "                if date_str not in GDP_data:\n",
    "                    GDP_data[date_str] = pd.DataFrame(columns=['Currency', 'GDP'])\n",
    "\n",
    "                GDP_data[date_str] = pd.concat([GDP_data[date_str], pd.DataFrame({'Currency': [currency], 'GDP': [row['GDP']]})], ignore_index=True)\n",
    "                \n",
    "\n",
    "        else:\n",
    "            print(f\"No data retrieved for {security}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving data for {security}: {e}\")\n",
    "\n",
    "\n",
    "for date_str in GDP_data:\n",
    "    GDP_data[date_str] = GDP_data[date_str].set_index('Currency')\n",
    "    GDP_data[date_str] = GDP_data[date_str].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program64\\Python\\Python\\lib\\site-packages\\blp\\blp.py:775: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pandas.concat(dfs)\n"
     ]
    }
   ],
   "source": [
    "from blp import blp \n",
    "bquery = blp.BlpQuery().start()\n",
    "strt_date = '20230101'\n",
    "end_date = pd.Timestamp('today').strftime('%Y%m%d')\n",
    "###########################################################################################################################################################\n",
    "###########################################################################################################################################################\n",
    "bquery = blp.BlpQuery().start()\n",
    "trade_balance_tickers = [\n",
    "    \"ECOYBBRN Index\", \"ECOYBCLN Index\", \"ECOYBCNN Index\", \"ECOYBCON Index\",\n",
    "    \"ECOYBCZN Index\", \"ECOYBHUN Index\", \"ECOYBIDN Index\", \"ECOYBMYN Index\",\n",
    "    \"ECOYBMXN Index\", \"PRTRBAL Index\", \"ECOYBPHN Index\", \"ECOYBPLN Index\",\n",
    "    \"ECOYBRON Index\", \"ECOYBRUN Index\", \"ECOYBZAN Index\", \"ECOYBTHN Index\",\n",
    "    \"ECOYBTRN Index\", \"ECOYBINN Index\", \"ECOYBSGN Index\", \"ECOYBTWN Index\",\n",
    "    \"ECOYBKRN Index\", \"ECOYBEGN Index\",\"ECOYBEGN Index\", \"ECOYBEAS Index\", \"ECOYBJPN Index\" \n",
    "]\n",
    "\n",
    "currencies = [\n",
    "    \"BRL\", \"CLP\", \"CNY\", \"COP\", \"CZK\", \"HUF\", \"IDR\", \"MYR\", \"MXN\", \"PEN\",\n",
    "    \"PHP\", \"PLN\", \"RON\", \"RUB\", \"ZAR\", \"THB\", \"TRY\", \"INR\", \"SGD\", \"TWD\",\n",
    "    \"KRW\", \"UAH\", \"EGP\", \"EUR\", \"JPY\"\n",
    "]\n",
    "\n",
    "TB_query = bquery.bdh(trade_balance_tickers, [\"PX_LAST\"],\n",
    "        start_date= strt_date, \n",
    "        end_date= end_date, \n",
    "        options={\"adjustmentSplit\": True, \"CDR\":\"5D\"})\n",
    "TB_query.rename(columns={'PX_LAST':'TB'}, inplace=True)\n",
    "\n",
    "# Create conditions dynamically\n",
    "conditions = [(TB_query['security'] == ticker) for ticker in trade_balance_tickers]\n",
    "\n",
    "TB_query['Currency'] = np.select(conditions, currencies, default=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_tb_dict(tb_df):\n",
    "    \"\"\"Creates a dictionary of DataFrames with Trade Balance data organized by date.\n",
    "\n",
    "    Args:\n",
    "        tb_df: The input DataFrame with 'date', 'security', 'TB', and 'Currency' columns.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary where keys are dates (YYYYMMDD strings) and values are DataFrames\n",
    "        with 'Currency' as index and 'TB' as a column.\n",
    "    \"\"\"\n",
    "\n",
    "    tb_dict = {}\n",
    "    for date, date_df in tb_df.groupby('date'): #Group by date\n",
    "        date_str = date.strftime('%Y%m%d')\n",
    "\n",
    "        # Create a dictionary entry for the date if it doens't exist yet\n",
    "        if date_str not in tb_dict:\n",
    "            tb_dict[date_str] = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "        # Efficiently creates the DataFrame with \"Currency\" as index and \"TB\" as column:\n",
    "        data = {currency: tb for currency, tb in zip(date_df['Currency'], date_df['TB'])} #uses zip to iterate through lists in parallel\n",
    "        temp_df = pd.DataFrame.from_dict(data, orient='index', columns=['TB']) #orient = index to have currency as index\n",
    "        temp_df = temp_df.reindex(currencies)\n",
    "        temp_df = temp_df.reset_index().rename(columns={'index':'Currency'}) \n",
    "\n",
    "        tb_dict[date_str] = temp_df #add or update date in dictionary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return tb_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_dict = create_tb_dict(TB_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_3m_tb_change(tb_dict):\n",
    "    \"\"\"Calculates the 3-month Trade Balance change for each DataFrame in the dictionary.\n",
    "\n",
    "    Args:\n",
    "        tb_dict: A dictionary where keys are dates ('YYYYMMDD') and values are DataFrames \n",
    "                 with 'Currency' as index and 'TB' as a column.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with the same structure as tb_dict, but with an additional 'TB_3m_Chg' column.\n",
    "    \"\"\"\n",
    "\n",
    "    tb_dict_with_change = {}\n",
    "    # treat trade balance PERU \n",
    "    \n",
    "    for date_str, df in tb_dict.items():  # Iterate through the dictionary\n",
    "        date = pd.to_datetime(date_str, format='%Y%m%d')  # Convert to datetime object\n",
    "\n",
    "        # Calculate the date three months prior (using the last day of the month for alignment):\n",
    "        three_months_ago = (date - pd.DateOffset(months=3)).strftime('%Y%m%d')\n",
    "\n",
    "\n",
    "        if three_months_ago in tb_dict:  # Only calculate if data for three months ago exists\n",
    "\n",
    "\n",
    "            df['TB_3m_Chg'] = df['TB'] - tb_dict[three_months_ago]['TB'] # Correct subtraction with aligned indices\n",
    "\n",
    "        # Handle missing data if 3 months ago date isn't present (fill, 0, etc.)\n",
    "        else:\n",
    "            df['TB_3m_Chg'] = np.nan # Or your preferred handling\n",
    "\n",
    "\n",
    "        tb_dict_with_change[date_str] = df  #Store modified DF in the dict\n",
    "\n",
    "\n",
    "    return tb_dict_with_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_dict_with_3m_change = calculate_3m_tb_change(tb_dict) #added this line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n",
      "Warning: No SETTLE_DT data found for CNY3M Curncy.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import blpapi\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta\n",
    "\n",
    "def get_settlement_dates(reference_date_str):\n",
    "    \"\"\"Retrieves settlement dates for the specified reference date.\"\"\"\n",
    "\n",
    "    request = refDataService.createRequest(\"ReferenceDataRequest\")\n",
    "    securities = [f\"{currency}3M Curncy\" for currency in currencies]\n",
    "    for sec in securities:\n",
    "        request.getElement(\"securities\").appendValue(sec)\n",
    "    request.getElement(\"fields\").appendValue(\"SETTLE_DT\")\n",
    "\n",
    "\n",
    "    overrides = request.getElement(\"overrides\")\n",
    "    override1 = overrides.appendElement()\n",
    "    override1.setElement(\"fieldId\", \"REFERENCE_DATE\")\n",
    "    override1.setElement(\"value\", reference_date_str)\n",
    "\n",
    "\n",
    "    session.sendRequest(request)\n",
    "    results = {}\n",
    "\n",
    "    while True:\n",
    "        ev = session.nextEvent()\n",
    "        if ev.eventType() == blpapi.Event.RESPONSE or ev.eventType() == blpapi.Event.PARTIAL_RESPONSE:\n",
    "            for msg in ev:\n",
    "                for securityData in msg.getElement(\"securityData\"):\n",
    "                    security = securityData.getElement(\"security\").getValueAsString()\n",
    "                    fieldData = securityData.getElement(\"fieldData\")\n",
    "                    if fieldData.numElements() > 0:\n",
    "                        settle_dt = fieldData.getElement(\"SETTLE_DT\").getValueAsString()\n",
    "                        results[security] = settle_dt\n",
    "                    else:\n",
    "                        print(f\"Warning: No SETTLE_DT data found for {security}.\")\n",
    "        if ev.eventType() == blpapi.Event.RESPONSE:\n",
    "            break\n",
    "            # ... (your existing code for processing the response)\n",
    "\n",
    "    settle_dates_df = pd.DataFrame.from_dict(results, orient='index', columns=['Settlement_Date'])\n",
    "    settle_dates_df.index.name = 'Security'\n",
    "    return settle_dates_df\n",
    "\n",
    "\n",
    "\n",
    "# Define date range (20 days ago to today)\n",
    "today = date.today()\n",
    "date_range = [today - timedelta(days=i) for i in range(50, -1, -1)]  # Includes today\n",
    "\n",
    "settlement_dates_dict = {}\n",
    "\n",
    "for d in date_range:\n",
    "    date_str = d.strftime(\"%Y%m%d\")\n",
    "    try:\n",
    "        settle_dates_df = get_settlement_dates(date_str)\n",
    "\n",
    "\n",
    "        settle_dates_df.reset_index(inplace=True)\n",
    "        # Check if CNY3M Curncy is missing and add it if necessary\n",
    "        if 'CNY3M Curncy' not in settle_dates_df['Security'].values:\n",
    "            new_row = {'Security': 'CNY3M Curncy', 'Settlement_Date': settle_dates_df['Settlement_Date'].iloc[0]} # Take first available settlement date\n",
    "            settle_dates_df = pd.concat([settle_dates_df, pd.DataFrame(new_row, index=[0])])\n",
    "            settle_dates_df.index = settle_dates_df.index.astype(str)\n",
    "            settle_dates_df.sort_index(inplace=True)  # Optional sorting\n",
    "\n",
    "\n",
    "        settlement_dates_dict[date_str] = settle_dates_df\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving data for {date_str}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# --- Currency extraction and reordering OUTSIDE the loop ---\n",
    "currency_order = ['BRL', 'CLP', 'CNY', 'COP', 'CZK', 'HUF', 'IDR', 'INR', 'KRW', 'MXN', \n",
    "                 'MYR', 'PEN', 'PHP', 'PLN', 'RON', 'RUB', 'SGD', 'THB', 'TRY', 'TWD', 'ZAR']\n",
    "for date_str, df in settlement_dates_dict.items():\n",
    "    df['Currency'] = df['Security'].str.slice(0, 3)\n",
    "    df['Currency'] = pd.Categorical(df['Currency'], categories=currency_order, ordered=True)\n",
    "    df.sort_values('Currency', inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Currency': ['BRL', 'CLP', 'CNY', 'COP', 'CZK', 'HUF', 'IDR', 'INR', 'KRW', 'MXN', 'MYR', 'PEN', 'PHP', 'PLN', 'RON', 'RUB', 'SGD', 'THB', 'TRY', 'TWD', 'UAH', 'ZAR', 'EUR', 'JPY', 'EGP', 'GBP', 'PY'],\n",
    "    'DayCount': [360, 360, 360, 360, 360, 360, 360, 360, 365, 360, 360, 360, 360, 365, 360, 360, 365, 365, 360, 365, 365, 365, 360, 360, 360, 360, 360],\n",
    "    'Multiplier': [10000, 1, 10000, 1, 1000, 100, 10000, 100, 1, 10000, 10000, 10000, 10000, 1, 10000, 10000, 100, 10000, 100, 100, 1, 10000, 1, 100, 10000, 10, 10000]\n",
    "}\n",
    "\n",
    "convention = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "reer_dict_final = reer_dict_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xbbg import blp \n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# Define the list of Bloomberg tickers\n",
    "tickers = [\"BRL BGN Curncy\", \"CLP BGN Curncy\", \"CNY CMPN Curncy\", \"COP REGN Curncy\",\n",
    "           \"CZK BGN Curncy\", \"HUF BGN Curncy\", \"IDR CMPN Curncy\", \"MYR CMPN Curncy\",\n",
    "           \"MXN BGN Curncy\", \"PEN BGN Curncy\", \"PHP CMPN Curncy\", \"PLN BGN Curncy\",\n",
    "           \"RON BGN Curncy\", \"RUB BGN Curncy\", \"ZAR BGN Curncy\", \"THB BGN Curncy\",\n",
    "           \"TRY BGN Curncy\", \"INR CMPN Curncy\", \"SGD BGN Curncy\", \"TWD BGN Curncy\",\n",
    "           \"KRW CMPN Curncy\"]\n",
    "\n",
    "# Extract currency codes from tickers\n",
    "currencies = [ticker[:3] for ticker in tickers]\n",
    "\n",
    "# Get historical data for the past 5 years\n",
    "end_date = pd.Timestamp.today()\n",
    "start_date = end_date - relativedelta(years=5)\n",
    "\n",
    "price_mid = blp.bdh(tickers, 'PX_MID', '20150101', end_date)\n",
    "price_mid.columns = currencies\n",
    "price_mid.index = price_mid.index.map(lambda x: x.strftime('%Y%m%d'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of dictionnaries \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "momentum_dict # good\n",
    "volatility_dict # good \n",
    "reer_dict_test # good reer_dict_final \n",
    "cpi_dict_2# ok\n",
    "fpa_dict# ok \n",
    "tb_dict_with_3m_change # \n",
    "data_prices # dataframe of all spots currencies OK \n",
    "settlement_dates_dict # all settlement dates dataframe  OK \n",
    "data # OK This is fixed \n",
    "discount_factors_dict # ok \n",
    "inflation \n",
    "# code rest of dictionnaries as spot returns, settlement dates, cpi mom/yoy, and rebuild the functions daily (fast) to get final columns Momentum\tREER discount\tMomentum-adjusted REER discount\t3m chg in TB%GDP\tNominal Carry\tReal Carry\tImplied Volatility Currency\tPortfolio Conviction\tPortfolio Size\tModel Conviction\tModel Size\n",
    "\n",
    "# recreate df for each month Index(['Currency', 'MOV_AVG_5D', 'MOV_AVG_20D', 'Momentum_x', '3M Implied Vol',\n",
    "       'CPI', 'REER_x', 'REER_5Y_avg_x', 'REER_y', 'REER_5Y_avg_y', 'spot_adj',\n",
    "       'infla_adj', 'proxy', 'REER_Discount_x', 'REER_Discount_y',\n",
    "       'Momentum_y', 'Conditional_REER_Discount', 'Symmetrical_REER_Discount',\n",
    "       'GDP', 'TB_3m_Chg_GDP', 'SPOT_MID', 'FWD_SCALE', 'FPA3M_MID',\n",
    "       'FPA1M_MID', 'security', 'TB', 'TB_3m_Chg', 'DayCount', 'Multiplier',\n",
    "       '3m_imp_yield', 'calculated_value', 'CPI YOY', 'Real_Carry',\n",
    "       'Nominal_carry', 'zscore_RN_part1', 'zscore_RN_part2',\n",
    "       'zscore_RN_part3', 'zscore_CN_part1', 'zscore_CN_part2',\n",
    "       'zscore_CN_part3', 'zscore_SN_part1', 'zscore_SN_part2',\n",
    "       'zscore_SN_part3', 'zscore_RR_part1', 'zscore_RR_part2',\n",
    "       'zscore_RR_part3', 'zscore_CR_part1', 'zscore_CR_part2',\n",
    "       'zscore_CR_part3', 'zscore_SR_part1', 'zscore_SR_part2',\n",
    "       'zscore_SR_part3', 'zscore_RN', 'zscore_CN', 'zscore_SN', 'zscore_RR',\n",
    "       'zscore_CR', 'zscore_SR'],\n",
    "      dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "reer_dict_final = {date_str.replace(\"-\", \"\"): df for date_str, df in reer_dict_final.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpi_dict_final = {date_str.replace(\"-\", \"\"): df for date_str, df in cpi_dict_2.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spot_prices = {}\n",
    "\n",
    "for date in price_mid.index:\n",
    "    spot_prices = price_mid.loc[date].dropna() # Drop currencies with NaN values for that date\n",
    "    spot_prices[date] = pd.DataFrame(spot_prices).transpose()  # Create a DataFrame for each date\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spot_prices = {}\n",
    "\n",
    "for date in price_mid.index:\n",
    "    spot_priceslocal = price_mid.loc[date]\n",
    "    spot_prices[date] = pd.DataFrame(spot_priceslocal).transpose()\n",
    "\n",
    "for date, prices_df in spot_prices.items():\n",
    "    # Transpose and rename columns\n",
    "    transposed_df = prices_df.transpose()  # Reset index to make 'index' a column\n",
    "    transposed_df.columns = ['SPOT_MID']\n",
    "\n",
    "    spot_prices[date] = transposed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date\n",
      "2024-01-01    5.3265\n",
      "2024-01-02    5.3301\n",
      "2024-01-03    5.3331\n",
      "2024-01-04    5.3298\n",
      "2024-01-05    5.3230\n",
      "               ...  \n",
      "2024-12-02    4.4512\n",
      "2024-12-03    4.4469\n",
      "2024-12-04    4.4329\n",
      "2024-12-05    4.4273\n",
      "2024-12-06    4.3938\n",
      "Name: PX_LAST, Length: 245, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from blp import blp\n",
    "import pandas as pd\n",
    "\n",
    "def get_daily_discount_factors(ticker, start_date, end_date):\n",
    "    \"\"\"Retrieves daily discount factors from Bloomberg.\n",
    "\n",
    "    Args:\n",
    "        ticker: Bloomberg ticker (e.g., \"USOSFRC Curncy\").\n",
    "        start_date: Start date as a string (YYYY-MM-DD).\n",
    "        end_date: End date as a string (YYYY-MM-DD).\n",
    "\n",
    "    Returns:\n",
    "        A pandas Series with dates as index and discount factors as values, or None if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        bquery = blp.BlpQuery().start()\n",
    "        df = bquery.bdh(\n",
    "            [ticker],\n",
    "            [\"PX_LAST\"],\n",
    "            start_date=start_date,\n",
    "            end_date=end_date,\n",
    "            options={\"adjustmentSplit\": True, \"CDR\": \"5D\"},  # Keep CDR option if needed\n",
    "        )\n",
    "\n",
    "        # Extract the discount factors and set the date as the index\n",
    "        discount_factors = df.set_index(\"date\")[\"PX_LAST\"]\n",
    "        return discount_factors\n",
    "\n",
    "    except Exception as e:  # Handle potential errors (e.g., connection issues)\n",
    "        print(f\"Error retrieving data: {e}\")\n",
    "        return None\n",
    "\n",
    "    finally:  # Ensure the Bloomberg connection is stopped\n",
    "        if bquery:\n",
    "            bquery.stop()\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "start_date = \"20240101\"\n",
    "end_date = today.strftime('%Y%m%d')\n",
    "ticker = \"USOSFRC Curncy\"\n",
    "\n",
    "discount_factors = get_daily_discount_factors(ticker, start_date, end_date)\n",
    "\n",
    "if discount_factors is not None:\n",
    "    print(discount_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "discount_factors_dict = {}\n",
    "\n",
    "for date, df in discount_factors.items():\n",
    "    if date not in discount_factors_dict:\n",
    "        formatted_date = date.strftime('%Y%m%d') #\n",
    "        discount_factors_dict[formatted_date] = {}  # Initialize inner dictionary\n",
    "        discount_factors_dict[formatted_date][ticker] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merged_dict = {}\n",
    "\n",
    "for date_str, momentum_df in momentum_dict.items():\n",
    "    if date_str in volatility_dict:  # Check if the date exists in both dictionaries\n",
    "        volatility_df = volatility_dict[date_str]\n",
    "\n",
    "        # Merge the DataFrames on the 'Currency' index\n",
    "        merged_df = pd.merge(momentum_df, volatility_df, left_index=True, right_index=True, how='inner', suffixes=('_mom', '_vol')) \n",
    "\n",
    "        merged_dict[date_str] = merged_df\n",
    "    else:\n",
    "        print(f\"Warning: Date {date_str} not found in both dictionaries. Skipping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_dict = {}\n",
    "for date_str, merged_df in merged_dict.items():\n",
    "    if date_str in reer_dict_final:\n",
    "        reer_df = reer_dict_final[date_str]\n",
    "        final_merged_df = pd.merge(reer_df.set_index('Currency'), merged_df, left_index=True, right_index=True, how='inner')\n",
    "        final_merged_dict[date_str] = final_merged_df\n",
    "    else: \n",
    "\n",
    "        print(f\"Warning: Date {date_str} not found in both dictionaries. Skipping.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_dict2 = {}\n",
    "for date_str, merged_df in final_merged_dict.items():\n",
    "    if date_str in cpi_dict_final:\n",
    "        cpi_df = cpi_dict_final[date_str]\n",
    "        final_merged_df = pd.merge(cpi_df.set_index('Currency'), merged_df, left_index=True, right_index=True, how='inner')\n",
    "        final_merged_dict2[date_str] = final_merged_df\n",
    "    else: \n",
    "\n",
    "        print(f\"Warning: Date {date_str} not found in both dictionaries. Skipping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_dict3 = {}\n",
    "for date_str, merged_df in final_merged_dict2.items():\n",
    "    if date_str in fpa_dict:\n",
    "        fpa_df = fpa_dict[date_str]\n",
    "        final_merged_df = pd.merge(fpa_df, merged_df, left_index=True, right_index=True, how='inner')\n",
    "        final_merged_dict3[date_str] = final_merged_df\n",
    "    else: \n",
    "\n",
    "        print(f\"Warning: Date {date_str} not found in both dictionaries. Skipping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_dict4 = {}\n",
    "for date_str, merged_df in final_merged_dict3.items():\n",
    "    if date_str in spot_prices:\n",
    "        spot_df = spot_prices[date_str]\n",
    "        final_merged_df = pd.merge(spot_df, merged_df, left_index=True, right_index=True, how='inner')\n",
    "        final_merged_dict4[date_str] = final_merged_df\n",
    "    else: \n",
    "\n",
    "        print(f\"Warning: Date {date_str} not found in both dictionaries. Skipping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with trade balance dict \n",
    "for date_str, merged_df in final_merged_dict4.items():\n",
    "    if date_str in tb_dict_with_3m_change:\n",
    "        tb_df = tb_dict_with_3m_change[date_str]\n",
    "        final_merged_df = pd.merge(tb_df.set_index('Currency'), merged_df, left_index=True, right_index=True, how='inner')\n",
    "        final_merged_dict4[date_str] = final_merged_df\n",
    "    else: \n",
    "\n",
    "        print(f\"Warning: Date {date_str} not found in both dictionaries. Skipping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_recent_gdp_date = max(GDP_data.keys())\n",
    "gdp_df = GDP_data[most_recent_gdp_date]\n",
    "\n",
    "for date_str, merged_df in final_merged_dict4.items():\n",
    "    if date_str in tb_dict_with_3m_change:\n",
    "        tb_df = tb_dict_with_3m_change[date_str]\n",
    "\n",
    "        try: #error handling if column doesn t exist\n",
    "            gdp_aligned = gdp_df.set_index('Currency').reindex(final_merged_df.index)\n",
    "\n",
    "            final_merged_df['TB_3m_Chg_GDP'] = final_merged_df['TB_3m_Chg'] / gdp_aligned['GDP']\n",
    "\n",
    "            final_merged_dict4[date_str] = final_merged_df\n",
    "\n",
    "        except KeyError as e:\n",
    "            print(f\"Warning: Column {e} not found for date {date_str}. Skipping calculation.\")\n",
    "            # Or log the error for better tracking\n",
    "    else:\n",
    "        print(f\"Warning: Date {date_str} not found in both dictionaries. Skipping.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "for date_str, df in final_merged_dict4.items():\n",
    "    df = df.reset_index()\n",
    "    df = df.drop(['DATE_vol', 'DATE_mom'], axis=1)\n",
    "\n",
    "    df.rename(columns={'index': 'Currency'}, inplace=True) #Rename the column to 'Currency'\n",
    "    final_merged_dict4[date_str] = df  # Update the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "import QuantLib as ql\n",
    "data = {\n",
    "    'Currency': ['BRL', 'CLP', 'CNY', 'COP', 'CZK', 'HUF', 'IDR', 'INR', 'KRW', 'MXN', 'MYR', 'PEN', 'PHP', 'PLN', 'RON', 'RUB', 'SGD', 'THB', 'TRY', 'TWD', 'UAH', 'ZAR', 'EUR', 'JPY', 'EGP', 'GBP', 'PY'],\n",
    "    'DayCount': [360, 360, 360, 360, 360, 360, 360, 360, 365, 360, 360, 360, 360, 365, 360, 360, 365, 365, 360, 365, 365, 365, 360, 360, 360, 360, 360],\n",
    "    'Multiplier': [10000, 1, 10000, 1, 1000, 100, 10000, 100, 1, 10000, 10000, 10000, 10000, 1, 10000, 10000, 100, 10000, 100, 100, 1, 10000, 1, 100, 10000, 10, 10000]\n",
    "}\n",
    "###########  GOOD  3 m implied yield##################\n",
    "\n",
    "convention = pd.DataFrame(data)\n",
    "def calculate_value(df, date_str):  # Add date_str as an argument\n",
    "    \"\"\"Calculates the value based on the provided formula, adapted for dictionary access.\n",
    "\n",
    "    Args:\n",
    "        df: The DataFrame for a specific date.\n",
    "        date_str: The date string key for accessing settlement_dates_dict.\n",
    "\n",
    "    Returns:\n",
    "        A Series containing the calculated values, or None if an error occurs.\n",
    "    \"\"\"\n",
    "    day_count = convention['DayCount']\n",
    "    try:\n",
    "        # Vectorized approach\n",
    "        settlement_dates = settlement_dates_dict[date_str]\n",
    "        settlement_dates = settlement_dates.drop_duplicates(subset='Currency', keep='first')\n",
    "\n",
    "        settlement_dates = settlement_dates.set_index('Currency')['Settlement_Date']\n",
    "        settlement_dates_ql = settlement_dates.apply(lambda x: ql.Date(x, '%Y-%m-%d'))\n",
    "        date_ql = ql.Date(date_str, '%Y%m%d')\n",
    "        total_days = settlement_dates_ql - date_ql\n",
    "        total_days = total_days.reindex(final_merged_dict4[date_str]['Currency'])\n",
    "\n",
    "        total_days = total_days.reset_index(drop=True)\n",
    "\n",
    "        frd_pts_ask = final_merged_dict4[date_str][\"FPA3M_MID\"]\n",
    "        spot = df['SPOT_MID']\n",
    "        discount_factor = discount_factors_dict[date_str]['USOSFRC Curncy']\n",
    "    \n",
    "\n",
    "\n",
    "        # Vectorized Calculation:\n",
    "        value = 100 * (\n",
    "            (1 + frd_pts_ask / spot)\n",
    "            * (1 + discount_factor / 100 * total_days / day_count)\n",
    "            - 1\n",
    "        ) * day_count / total_days\n",
    "        return value  # Return the calculated Series\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating values for {date_str}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for date_str, df in final_merged_dict4.items():\n",
    "    #print(final_merged_dict4[date_str]['FPA3M_MID'])\n",
    "    # Apply the function\n",
    "    try:\n",
    "        df['3m_imp_yield'] = calculate_value(df, date_str)\n",
    "        \n",
    "    except Exception as e: # Handle cases where the date might be missing or data is inconsistent\n",
    "        print(f\"Error processing date {date_str}. Skipping. Error: {e}\")\n",
    "        continue\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xbbg import blp\n",
    "\n",
    "def calculate_real_carry(df, date_str, inflation): # Add date_str and inflation arguments\n",
    "    \"\"\"Calculates real carry, adapted for dictionary and vectorized operations.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame for the specific date.\n",
    "        date_str: Not used in this function (kept for consistency with other functions).\n",
    "        inflation: The inflation DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A Series with calculated real carry values, or None if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        imp_yield = df['3m_imp_yield']\n",
    "        discount_factor = discount_factors_dict[date_str]['USOSFRC Curncy'] # Access from dictionary\n",
    "        \n",
    "        # Merge inflation data with df based on 'Currency'\n",
    "        df = pd.merge(df, inflation, on='Currency', how='left')  # Left merge to keep all currencies in df\n",
    "        cpi_emergent = df['CPI YOY']  # Access CPI from the merged DataFrame\n",
    "\n",
    "\n",
    "        cpi_us = blp.bdp(['CPI YOY Index'], 'last_price').values[0][0]\n",
    "\n",
    "\n",
    "        real_carry = ((1 + imp_yield / 100) / (1 + cpi_emergent / 100)\n",
    "                     - (1 + discount_factor / 100) / (1 + cpi_us / 100))\n",
    "        return real_carry\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating real carry for {date_str}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "for date_str, df in final_merged_dict4.items():\n",
    "    try:\n",
    "\n",
    "        df['Real_Carry'] = calculate_real_carry(df, date_str, inflation)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing date {date_str}: {e}\")\n",
    "        continue  # Or handle the error as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_nominal_carry(df, date_str):  # Add date_str argument\n",
    "    \"\"\"Calculates nominal carry, adapted for dictionary access and vectorized operations.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame for the specific date.\n",
    "        date_str: The date string for accessing discount factors.\n",
    "\n",
    "    Returns:\n",
    "        A Series of calculated nominal carry values or None if an error occurs.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        imp_yield = df['3m_imp_yield']\n",
    "        discount_factor = discount_factors_dict[date_str]['USOSFRC Curncy'] # Access from dict\n",
    "\n",
    "        # Vectorized Calculation\n",
    "        nominal_carry = ((1 + imp_yield / 100) / (1 + discount_factor / 100) - 1)\n",
    "        return nominal_carry\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating nominal carry for {date_str}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for date_str, df in final_merged_dict4.items():\n",
    "    try:\n",
    "        df['Nominal_carry'] = calculate_nominal_carry(df, date_str)\n",
    "\n",
    "    except Exception as e:  # Handle potential errors (missing data, type errors)\n",
    "        print(f\"Error processing date {date_str}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_symmetrical_reer(df):\n",
    "    \"\"\"Calculates Symmetrical REER Discount based on the Excel logic.\"\"\"\n",
    "    if 'REER_Discount' not in df.columns:\n",
    "        print(f\"Warning: 'REER_Discount' column not found for date {date}. Skipping calculation.\")  #or logging\n",
    "        return df  \n",
    "\n",
    "    df['Symmetrical_REER_Discount'] = df.apply(\n",
    "        lambda row: row['REER_Discount'] * (\n",
    "            1 if (row['Momentum'] == 1 and row['REER_Discount'] < 0) or (row['Momentum'] == -1 and row['REER_Discount'] > 0)\n",
    "            else 0\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    \n",
    "    # Calculate average standard deviation for currencies (excluding 'Avg/Std' row)\n",
    "    #currencies_df = df[df['Currency'] != 'Avg/Std']\n",
    "    #avg_std = currencies_df['Symmetrical_REER_Discount'].std()\n",
    "\n",
    "    # Update 'Avg/Std' row\n",
    "    #df.loc[df['Currency'] == 'Avg/Std', 'Symmetrical_REER_Discount'] = avg_std\n",
    "\n",
    "    return df\n",
    "\n",
    "for date, df in final_merged_dict4.items():\n",
    "    final_merged_dict4[date] = calculate_symmetrical_reer(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_conditional_reer(df):\n",
    "    \"\"\"\n",
    "    Adds 'Conditional_REER_Discount' column if it doesn't exist.\n",
    "    \"\"\"\n",
    "    if 'REER_Discount' not in df.columns:\n",
    "        print(f\"Warning: 'REER_Discount' column not found for date {date}. Skipping calculation.\")  #or logging\n",
    "        return df\n",
    "    if 'Conditional_REER_Discount' not in df.columns:\n",
    "        df['Conditional_REER_Discount'] = df.apply(\n",
    "            lambda row: row['Momentum'] * row['REER_Discount'] * (row['REER_Discount'] < 0) if row['Momentum'] == 1 else 0, \n",
    "            axis=1\n",
    "        )\n",
    "    return df\n",
    "\n",
    "\n",
    "# Apply the function to each DataFrame in the dictionary\n",
    "for date, df in final_merged_dict4.items():\n",
    "    final_merged_dict4[date] = add_conditional_reer(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ADAPTED Z SCORE FUNCTION #######\n",
    "models = {  # Dictionary mapping short model names to criteria lists\n",
    "    \"RN\": [\"REER_Discount\", \"TB_3m_Chg_GDP\", \"Nominal_carry\"],\n",
    "    \"CN\": [\"Conditional_REER_Discount\", \"TB_3m_Chg_GDP\", \"Nominal_carry\"],\n",
    "    \"SN\": [\"Symmetrical_REER_Discount\", \"TB_3m_Chg_GDP\", \"Nominal_carry\"],\n",
    "    \"RR\": [\"REER_Discount\", \"TB_3m_Chg_GDP\", \"Real_Carry\"],\n",
    "    \"CR\": [\"Conditional_REER_Discount\", \"TB_3m_Chg_GDP\", \"Real_Carry\"],\n",
    "    \"SR\": [\"Symmetrical_REER_Discount\", \"TB_3m_Chg_GDP\", \"Real_Carry\"],\n",
    "}\n",
    "def calculate_zscore(df, criteria):\n",
    "    \"\"\"Calculates the z-score based on the provided criteria.\"\"\"\n",
    "    zscore_parts = []\n",
    "\n",
    "    for i, criterion in enumerate(criteria):\n",
    "        if df[criterion].std() == 0:  # Handle zero standard deviation\n",
    "            zscore_part = 0\n",
    "        elif criterion in [\"Symmetrical_REER_Discount\", \"Conditional_REER_Discount\"]:\n",
    "            zscore_part = -df[criterion] / df[criterion].std()\n",
    "        else:\n",
    "            zscore_part = df[criterion] / df[criterion].std()\n",
    "\n",
    "        zscore_parts.append(zscore_part)\n",
    "\n",
    "    # Return NA for the 'Avg/Std' row\n",
    "    return np.where(df['Currency'] == 'Avg/Std', np.nan, sum(zscore_parts)/3)\n",
    "\n",
    "\n",
    "# Loop through each date in the dictionary\n",
    "for date, df in final_merged_dict4.items():\n",
    "    print(date)\n",
    "    # Find the recommended model for the current date\n",
    "    model_row = model_list[model_list['Date'] == date]\n",
    "    \n",
    "    if not model_row.empty:\n",
    "        model_name = model_row['model'].iloc[0][:2]  # Extract first two characters (e.g., \"SN\", \"RN\")\n",
    "        criteria = models[model_name]  # Get criteria for the model\n",
    "\n",
    "\n",
    "        df['z_score'] = calculate_zscore(df, criteria)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "models = {\n",
    "    \"RN\": [\"REER_Discount_x\", \"TB_3m_Chg_GDP\", \"Nominal_carry\"],\n",
    "    \"CN\": [\"Conditional_REER_Discount\", \"TB_3m_Chg_GDP\", \"Nominal_carry\"],\n",
    "    \"SN\": [\"Symmetrical_REER_Discount\", \"TB_3m_Chg_GDP\", \"Nominal_carry\"],\n",
    "    \"RR\": [\"REER_Discount_x\", \"TB_3m_Chg_GDP\", \"Real_Carry\"],\n",
    "    \"CR\": [\"Conditional_REER_Discount\", \"TB_3m_Chg_GDP\", \"Real_Carry\"],\n",
    "    \"SR\": [\"Symmetrical_REER_Discount\", \"TB_3m_Chg_GDP\", \"Real_Carry\"],\n",
    "}\n",
    "\n",
    "def round_2x_to_half(x):\n",
    "    two_x = 2 * x\n",
    "    return round(two_x * 2) / 2 if two_x >= 0 else -np.round(-two_x * 2) / 2\n",
    "\n",
    "# Conviction mapping dictionaries (define outside the function)\n",
    "conviction_mapping_agnostic = {  # No change here\n",
    "    0: 3, 1: 3, 2: 2, 3: 2, 4: 2, 5: 1, 6: 1, 7: 1,\n",
    "    8: 0, 9: 0, 10: 0, 11: 0, 12: -1, 13: -1, 14: -1,\n",
    "    15: -2, 16: -2, 17: -2, 18: -3, 19: -3\n",
    "}\n",
    "\n",
    "\n",
    "def calculate_conviction_and_zscore(df, model_name):\n",
    "    \"\"\"Calculates both conviction and z-score, handling 'Avg/Std' row and NaNs.\"\"\"\n",
    "\n",
    "    model_type = model_name.split(\"-\")[1]\n",
    "    short_model_name = model_name[:2]\n",
    "    criteria = models.get(short_model_name)\n",
    "\n",
    "    if criteria:\n",
    "        # Filter out \"Avg/Std\" *before* calculations:\n",
    "        df_currencies = df[df['Currency'] != 'Avg/Std'].copy()  #Important: create a copy to avoid SettingWithCopyWarning\n",
    "\n",
    "\n",
    "\n",
    "        # 1. Calculate Z-score:\n",
    "        df_currencies[f'zscore_{short_model_name}'] = calculate_zscore(df_currencies, criteria)\n",
    "\n",
    "        # 2. Calculate Rank (and fill NaNs if any):\n",
    "        df_currencies[f'rank_{short_model_name}'] = df_currencies[f'zscore_{short_model_name}'].rank(ascending=False, method='dense').fillna(-1).astype(int)\n",
    "\n",
    "\n",
    "        # 3. Calculate Conviction:\n",
    "        if model_type == 'Agn':\n",
    "            df_sorted = df_currencies.sort_values(by=f'rank_{short_model_name}')\n",
    "\n",
    "            df_sorted[f'conviction_{model_name}'] = df_sorted[f'rank_{short_model_name}'].apply(\n",
    "                 lambda rank: conviction_mapping_agnostic.get(int(rank) - 1, np.nan) if not pd.isna(rank) else None)\n",
    "\n",
    "            df = df.merge(df_sorted[[f'conviction_{model_name}', 'Currency']], on='Currency', how='left') #Important: add currency to merge on\n",
    "\n",
    "        elif model_type == 'Awa':\n",
    "\n",
    "            df_currencies[f'conviction_{model_name}'] = df_currencies.apply(\n",
    "                lambda row: _calculate_awa_conviction(row, short_model_name), axis=1\n",
    "             )\n",
    "            df = df.merge(df_currencies[[f'conviction_{model_name}', 'Currency']], on='Currency', how='left')#Merge the result back\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "def _calculate_awa_conviction(row, model_name): #Correct the ranges \n",
    "    try:\n",
    "        rank = int(row[f'rank_{model_name}'])\n",
    "    except (ValueError, TypeError):  #Catching more types of errors\n",
    "        return np.nan  # Or another default value as needed\n",
    "\n",
    "\n",
    "    zscore = row[f'zscore_{model_name}']\n",
    "    if rank <= 8:\n",
    "        conviction = max(-3, min(3, np.round(zscore * 4)/2 ))\n",
    "    elif rank <=12: #Between 9 and 12\n",
    "        conviction=0\n",
    "    elif rank >= 13 :# >= 13\n",
    "\n",
    "        conviction = max(-3, min(3, round_2x_to_half(zscore)))\n",
    "    else:\n",
    "        return np.nan\n",
    "    return conviction \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Main loop:\n",
    "# Ensure 'Date' in model_list is datetime64[ns] type:\n",
    "model_list['Date'] = model_list['Date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "for date_str, df in date_metric_dictionary.items():\n",
    "    #Ensure also that your dictionnary keys are in datetime format, without time \n",
    "    date = pd.to_datetime(date_str).strftime('%Y-%m-%d')#Remove time from timestamp\n",
    "    \n",
    "    model_row = model_list[model_list['Date'] == date]\n",
    "\n",
    "    if not model_row.empty:\n",
    "\n",
    "        model_name = model_row['model'].iloc[0]\n",
    "        date_metric_dictionary[date_str] = calculate_conviction_and_zscore(df.copy(), model_name) \n",
    "\n",
    "    else:\n",
    "        print(f\"No model found for {date}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Currency</th>\n",
       "      <th>TB</th>\n",
       "      <th>TB_3m_Chg</th>\n",
       "      <th>SPOT_MID</th>\n",
       "      <th>FPA3M_MID</th>\n",
       "      <th>CPI</th>\n",
       "      <th>REER</th>\n",
       "      <th>REER_5Y_avg</th>\n",
       "      <th>spot_adj</th>\n",
       "      <th>infla_adj</th>\n",
       "      <th>...</th>\n",
       "      <th>MOV_AVG_5D</th>\n",
       "      <th>MOV_AVG_20D</th>\n",
       "      <th>Momentum</th>\n",
       "      <th>3M Implied Vol</th>\n",
       "      <th>TB_3m_Chg_GDP</th>\n",
       "      <th>3m_imp_yield</th>\n",
       "      <th>Real_Carry</th>\n",
       "      <th>Nominal_carry</th>\n",
       "      <th>Symmetrical_REER_Discount</th>\n",
       "      <th>Conditional_REER_Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRL</td>\n",
       "      <td>79.20</td>\n",
       "      <td>-10.9</td>\n",
       "      <td>6.07980</td>\n",
       "      <td>0.075493</td>\n",
       "      <td>0.44</td>\n",
       "      <td>103.66</td>\n",
       "      <td>106.868361</td>\n",
       "      <td>-0.029861</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0503</td>\n",
       "      <td>5.8736</td>\n",
       "      <td>1</td>\n",
       "      <td>13.8900</td>\n",
       "      <td>-0.005015</td>\n",
       "      <td>9.203825</td>\n",
       "      <td>0.024936</td>\n",
       "      <td>0.046076</td>\n",
       "      <td>-0.059051</td>\n",
       "      <td>-0.059051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CLP</td>\n",
       "      <td>21.50</td>\n",
       "      <td>1.8</td>\n",
       "      <td>975.45000</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>102.22</td>\n",
       "      <td>102.706557</td>\n",
       "      <td>0.006366</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>...</td>\n",
       "      <td>974.2300</td>\n",
       "      <td>976.5800</td>\n",
       "      <td>-1</td>\n",
       "      <td>13.1000</td>\n",
       "      <td>0.005365</td>\n",
       "      <td>4.870346</td>\n",
       "      <td>-0.015856</td>\n",
       "      <td>0.004565</td>\n",
       "      <td>0.001677</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNY</td>\n",
       "      <td>929.10</td>\n",
       "      <td>46.5</td>\n",
       "      <td>7.27170</td>\n",
       "      <td>-0.031829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.01</td>\n",
       "      <td>98.39377</td>\n",
       "      <td>-0.009856</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>...</td>\n",
       "      <td>7.2710</td>\n",
       "      <td>7.2468</td>\n",
       "      <td>1</td>\n",
       "      <td>6.2800</td>\n",
       "      <td>0.002613</td>\n",
       "      <td>2.623753</td>\n",
       "      <td>0.005685</td>\n",
       "      <td>-0.016955</td>\n",
       "      <td>-0.074098</td>\n",
       "      <td>-0.074098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COP</td>\n",
       "      <td>-9.80</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>4404.12500</td>\n",
       "      <td>51.137</td>\n",
       "      <td>0.24</td>\n",
       "      <td>104.64</td>\n",
       "      <td>99.188197</td>\n",
       "      <td>0.022036</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>...</td>\n",
       "      <td>4428.5800</td>\n",
       "      <td>4418.3800</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0925</td>\n",
       "      <td>-0.000550</td>\n",
       "      <td>8.891644</td>\n",
       "      <td>0.015546</td>\n",
       "      <td>0.043085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CZK</td>\n",
       "      <td>9.80</td>\n",
       "      <td>0.4</td>\n",
       "      <td>23.77055</td>\n",
       "      <td>-0.04859</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>119.03</td>\n",
       "      <td>111.737541</td>\n",
       "      <td>0.002319</td>\n",
       "      <td>-0.003515</td>\n",
       "      <td>...</td>\n",
       "      <td>23.8813</td>\n",
       "      <td>23.9580</td>\n",
       "      <td>-1</td>\n",
       "      <td>8.4950</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>3.601962</td>\n",
       "      <td>-0.009682</td>\n",
       "      <td>-0.007585</td>\n",
       "      <td>0.067007</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HUF</td>\n",
       "      <td>12.40</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>392.34100</td>\n",
       "      <td>1.7</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>106.12</td>\n",
       "      <td>102.799016</td>\n",
       "      <td>-0.020019</td>\n",
       "      <td>-0.000306</td>\n",
       "      <td>...</td>\n",
       "      <td>393.0500</td>\n",
       "      <td>389.7800</td>\n",
       "      <td>1</td>\n",
       "      <td>11.3925</td>\n",
       "      <td>-0.002825</td>\n",
       "      <td>6.072272</td>\n",
       "      <td>0.010349</td>\n",
       "      <td>0.016078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>IDR</td>\n",
       "      <td>30.10</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>15853.00000</td>\n",
       "      <td>57.0</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>99.73</td>\n",
       "      <td>100.533115</td>\n",
       "      <td>0.003630</td>\n",
       "      <td>-0.001191</td>\n",
       "      <td>...</td>\n",
       "      <td>15896.0000</td>\n",
       "      <td>15848.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>7.2000</td>\n",
       "      <td>-0.000875</td>\n",
       "      <td>5.786611</td>\n",
       "      <td>0.022597</td>\n",
       "      <td>0.013342</td>\n",
       "      <td>-0.004617</td>\n",
       "      <td>-0.004617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MYR</td>\n",
       "      <td>27.50</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>4.42200</td>\n",
       "      <td>-0.01152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.11</td>\n",
       "      <td>97.83918</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>-0.000175</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4454</td>\n",
       "      <td>4.4545</td>\n",
       "      <td>-1</td>\n",
       "      <td>6.4250</td>\n",
       "      <td>-0.005505</td>\n",
       "      <td>3.384634</td>\n",
       "      <td>-0.002914</td>\n",
       "      <td>-0.009667</td>\n",
       "      <td>0.035618</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MXN</td>\n",
       "      <td>-5.80</td>\n",
       "      <td>1.7</td>\n",
       "      <td>20.23115</td>\n",
       "      <td>0.303254</td>\n",
       "      <td>0.05</td>\n",
       "      <td>121.26</td>\n",
       "      <td>115.177541</td>\n",
       "      <td>-0.003822</td>\n",
       "      <td>-0.000356</td>\n",
       "      <td>...</td>\n",
       "      <td>20.2920</td>\n",
       "      <td>20.3733</td>\n",
       "      <td>-1</td>\n",
       "      <td>13.2080</td>\n",
       "      <td>0.000950</td>\n",
       "      <td>10.280046</td>\n",
       "      <td>0.035209</td>\n",
       "      <td>0.056385</td>\n",
       "      <td>0.048714</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PEN</td>\n",
       "      <td>2342.87</td>\n",
       "      <td>337.8</td>\n",
       "      <td>3.72123</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>102.27</td>\n",
       "      <td>97.508525</td>\n",
       "      <td>0.033442</td>\n",
       "      <td>-0.001969</td>\n",
       "      <td>...</td>\n",
       "      <td>3.7358</td>\n",
       "      <td>3.7712</td>\n",
       "      <td>-1</td>\n",
       "      <td>6.9100</td>\n",
       "      <td>1.262318</td>\n",
       "      <td>4.966339</td>\n",
       "      <td>0.011497</td>\n",
       "      <td>0.005484</td>\n",
       "      <td>0.083492</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PHP</td>\n",
       "      <td>-52.60</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>57.85350</td>\n",
       "      <td>0.1075</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>99.92</td>\n",
       "      <td>100.024098</td>\n",
       "      <td>0.018953</td>\n",
       "      <td>-0.001615</td>\n",
       "      <td>...</td>\n",
       "      <td>58.2270</td>\n",
       "      <td>58.6600</td>\n",
       "      <td>-1</td>\n",
       "      <td>6.4550</td>\n",
       "      <td>-0.003431</td>\n",
       "      <td>5.145221</td>\n",
       "      <td>0.010329</td>\n",
       "      <td>0.007198</td>\n",
       "      <td>0.017574</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PLN</td>\n",
       "      <td>4.50</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>4.04026</td>\n",
       "      <td>0.016062</td>\n",
       "      <td>0.1</td>\n",
       "      <td>121.96</td>\n",
       "      <td>105.740656</td>\n",
       "      <td>0.015697</td>\n",
       "      <td>0.00175</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0638</td>\n",
       "      <td>4.0915</td>\n",
       "      <td>-1</td>\n",
       "      <td>10.1125</td>\n",
       "      <td>-0.001109</td>\n",
       "      <td>5.933833</td>\n",
       "      <td>-0.00859</td>\n",
       "      <td>0.014752</td>\n",
       "      <td>0.171889</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RON</td>\n",
       "      <td>-34.70</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>4.70390</td>\n",
       "      <td>0.025098</td>\n",
       "      <td>0.33</td>\n",
       "      <td>112.98</td>\n",
       "      <td>104.674426</td>\n",
       "      <td>-0.000650</td>\n",
       "      <td>0.004026</td>\n",
       "      <td>...</td>\n",
       "      <td>4.7244</td>\n",
       "      <td>4.7198</td>\n",
       "      <td>1</td>\n",
       "      <td>7.2550</td>\n",
       "      <td>-0.001424</td>\n",
       "      <td>6.460653</td>\n",
       "      <td>-0.000376</td>\n",
       "      <td>0.019799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RUB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.55009</td>\n",
       "      <td>3.60805</td>\n",
       "      <td>0.48</td>\n",
       "      <td>96.13</td>\n",
       "      <td>106.381311</td>\n",
       "      <td>-0.018707</td>\n",
       "      <td>0.005243</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>24.2550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.104058</td>\n",
       "      <td>0.079845</td>\n",
       "      <td>0.140911</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ZAR</td>\n",
       "      <td>8.30</td>\n",
       "      <td>1.6</td>\n",
       "      <td>17.99864</td>\n",
       "      <td>0.14683</td>\n",
       "      <td>0.1</td>\n",
       "      <td>106.29</td>\n",
       "      <td>103.883115</td>\n",
       "      <td>-0.005062</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0921</td>\n",
       "      <td>18.1075</td>\n",
       "      <td>-1</td>\n",
       "      <td>12.5200</td>\n",
       "      <td>0.004235</td>\n",
       "      <td>7.553923</td>\n",
       "      <td>0.028761</td>\n",
       "      <td>0.030271</td>\n",
       "      <td>0.018253</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>THB</td>\n",
       "      <td>-7.50</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>34.07140</td>\n",
       "      <td>-0.18757</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>98.05</td>\n",
       "      <td>96.014754</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>-0.000444</td>\n",
       "      <td>...</td>\n",
       "      <td>34.3190</td>\n",
       "      <td>34.5540</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.7225</td>\n",
       "      <td>-0.004661</td>\n",
       "      <td>2.261235</td>\n",
       "      <td>-0.003289</td>\n",
       "      <td>-0.020428</td>\n",
       "      <td>0.022564</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TRY</td>\n",
       "      <td>-77.90</td>\n",
       "      <td>0.7</td>\n",
       "      <td>34.78835</td>\n",
       "      <td>3.34772</td>\n",
       "      <td>2.97</td>\n",
       "      <td>99.36</td>\n",
       "      <td>91.45623</td>\n",
       "      <td>0.011275</td>\n",
       "      <td>0.030044</td>\n",
       "      <td>...</td>\n",
       "      <td>34.7416</td>\n",
       "      <td>34.5638</td>\n",
       "      <td>1</td>\n",
       "      <td>13.6600</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>43.843658</td>\n",
       "      <td>-0.049361</td>\n",
       "      <td>0.377895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>INR</td>\n",
       "      <td>-257.10</td>\n",
       "      <td>2.6</td>\n",
       "      <td>84.70376</td>\n",
       "      <td>0.44525</td>\n",
       "      <td>4.52099</td>\n",
       "      <td>103.17</td>\n",
       "      <td>100.301967</td>\n",
       "      <td>0.010091</td>\n",
       "      <td>0.045202</td>\n",
       "      <td>...</td>\n",
       "      <td>84.7133</td>\n",
       "      <td>84.4858</td>\n",
       "      <td>1</td>\n",
       "      <td>3.2275</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>6.458005</td>\n",
       "      <td>-0.015148</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SGD</td>\n",
       "      <td>49.20</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>1.34165</td>\n",
       "      <td>-0.00532</td>\n",
       "      <td>0.3</td>\n",
       "      <td>116.53</td>\n",
       "      <td>105.919344</td>\n",
       "      <td>-0.002785</td>\n",
       "      <td>0.003209</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3429</td>\n",
       "      <td>1.3423</td>\n",
       "      <td>1</td>\n",
       "      <td>5.8625</td>\n",
       "      <td>-0.001795</td>\n",
       "      <td>2.857909</td>\n",
       "      <td>-0.003106</td>\n",
       "      <td>-0.014712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TWD</td>\n",
       "      <td>87.50</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>32.38500</td>\n",
       "      <td>-0.2195</td>\n",
       "      <td>0.11</td>\n",
       "      <td>97.47</td>\n",
       "      <td>100.060984</td>\n",
       "      <td>0.003105</td>\n",
       "      <td>0.001345</td>\n",
       "      <td>...</td>\n",
       "      <td>32.4850</td>\n",
       "      <td>32.4890</td>\n",
       "      <td>-1</td>\n",
       "      <td>6.7800</td>\n",
       "      <td>-0.000093</td>\n",
       "      <td>1.732203</td>\n",
       "      <td>-0.017068</td>\n",
       "      <td>-0.025496</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>KRW</td>\n",
       "      <td>49.60</td>\n",
       "      <td>6.4</td>\n",
       "      <td>1423.57500</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>93.64</td>\n",
       "      <td>97.69918</td>\n",
       "      <td>-0.022336</td>\n",
       "      <td>0.001174</td>\n",
       "      <td>...</td>\n",
       "      <td>1417.2300</td>\n",
       "      <td>1403.6900</td>\n",
       "      <td>1</td>\n",
       "      <td>9.8875</td>\n",
       "      <td>0.003737</td>\n",
       "      <td>2.959385</td>\n",
       "      <td>-0.001103</td>\n",
       "      <td>-0.01374</td>\n",
       "      <td>-0.062743</td>\n",
       "      <td>-0.062743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Currency       TB  TB_3m_Chg     SPOT_MID FPA3M_MID      CPI    REER  \\\n",
       "0       BRL    79.20      -10.9      6.07980  0.075493     0.44  103.66   \n",
       "1       CLP    21.50        1.8    975.45000       1.2      0.1  102.22   \n",
       "2       CNY   929.10       46.5      7.27170 -0.031829      0.0   92.01   \n",
       "3       COP    -9.80       -0.2   4404.12500    51.137     0.24  104.64   \n",
       "4       CZK     9.80        0.4     23.77055  -0.04859     -0.4  119.03   \n",
       "5       HUF    12.40       -0.6    392.34100       1.7     -0.1  106.12   \n",
       "6       IDR    30.10       -1.2  15853.00000      57.0    -0.12   99.73   \n",
       "7       MYR    27.50       -2.2      4.42200  -0.01152      0.0  101.11   \n",
       "8       MXN    -5.80        1.7     20.23115  0.303254     0.05  121.26   \n",
       "9       PEN  2342.87      337.8      3.72123    0.0055    -0.12  102.27   \n",
       "10      PHP   -52.60       -1.5     57.85350    0.1075     -0.2   99.92   \n",
       "11      PLN     4.50       -0.9      4.04026  0.016062      0.1  121.96   \n",
       "12      RON   -34.70       -0.5      4.70390  0.025098     0.33  112.98   \n",
       "13      RUB      NaN        NaN    100.55009   3.60805     0.48   96.13   \n",
       "14      ZAR     8.30        1.6     17.99864   0.14683      0.1  106.29   \n",
       "15      THB    -7.50       -2.4     34.07140  -0.18757     -0.1   98.05   \n",
       "16      TRY   -77.90        0.7     34.78835   3.34772     2.97   99.36   \n",
       "17      INR  -257.10        2.6     84.70376   0.44525  4.52099  103.17   \n",
       "18      SGD    49.20       -0.9      1.34165  -0.00532      0.3  116.53   \n",
       "19      TWD    87.50       -2.1     32.38500   -0.2195     0.11   97.47   \n",
       "20      KRW    49.60        6.4   1423.57500      -5.2      0.1   93.64   \n",
       "\n",
       "   REER_5Y_avg  spot_adj infla_adj  ...  MOV_AVG_5D MOV_AVG_20D  Momentum  \\\n",
       "0   106.868361 -0.029861 -0.000357  ...      6.0503      5.8736         1   \n",
       "1   102.706557  0.006366  0.000407  ...    974.2300    976.5800        -1   \n",
       "2     98.39377 -0.009856 -0.000013  ...      7.2710      7.2468         1   \n",
       "3    99.188197  0.022036  0.001615  ...   4428.5800   4418.3800         1   \n",
       "4   111.737541  0.002319 -0.003515  ...     23.8813     23.9580        -1   \n",
       "5   102.799016 -0.020019 -0.000306  ...    393.0500    389.7800         1   \n",
       "6   100.533115  0.003630 -0.001191  ...  15896.0000  15848.0000         1   \n",
       "7     97.83918  0.002151 -0.000175  ...      4.4454      4.4545        -1   \n",
       "8   115.177541 -0.003822 -0.000356  ...     20.2920     20.3733        -1   \n",
       "9    97.508525  0.033442 -0.001969  ...      3.7358      3.7712        -1   \n",
       "10  100.024098  0.018953 -0.001615  ...     58.2270     58.6600        -1   \n",
       "11  105.740656  0.015697   0.00175  ...      4.0638      4.0915        -1   \n",
       "12  104.674426 -0.000650  0.004026  ...      4.7244      4.7198         1   \n",
       "13  106.381311 -0.018707  0.005243  ...         NaN         NaN        -1   \n",
       "14  103.883115 -0.005062  0.001335  ...     18.0921     18.1075        -1   \n",
       "15   96.014754  0.001425 -0.000444  ...     34.3190     34.5540        -1   \n",
       "16    91.45623  0.011275  0.030044  ...     34.7416     34.5638         1   \n",
       "17  100.301967  0.010091  0.045202  ...     84.7133     84.4858         1   \n",
       "18  105.919344 -0.002785  0.003209  ...      1.3429      1.3423         1   \n",
       "19  100.060984  0.003105  0.001345  ...     32.4850     32.4890        -1   \n",
       "20    97.69918 -0.022336  0.001174  ...   1417.2300   1403.6900         1   \n",
       "\n",
       "    3M Implied Vol  TB_3m_Chg_GDP  3m_imp_yield  Real_Carry Nominal_carry  \\\n",
       "0          13.8900      -0.005015      9.203825    0.024936      0.046076   \n",
       "1          13.1000       0.005365      4.870346   -0.015856      0.004565   \n",
       "2           6.2800       0.002613      2.623753    0.005685     -0.016955   \n",
       "3          13.0925      -0.000550      8.891644    0.015546      0.043085   \n",
       "4           8.4950       0.001209      3.601962   -0.009682     -0.007585   \n",
       "5          11.3925      -0.002825      6.072272    0.010349      0.016078   \n",
       "6           7.2000      -0.000875      5.786611    0.022597      0.013342   \n",
       "7           6.4250      -0.005505      3.384634   -0.002914     -0.009667   \n",
       "8          13.2080       0.000950     10.280046    0.035209      0.056385   \n",
       "9           6.9100       1.262318      4.966339    0.011497      0.005484   \n",
       "10          6.4550      -0.003431      5.145221    0.010329      0.007198   \n",
       "11         10.1125      -0.001109      5.933833    -0.00859      0.014752   \n",
       "12          7.2550      -0.001424      6.460653   -0.000376      0.019799   \n",
       "13         24.2550            NaN     19.104058    0.079845      0.140911   \n",
       "14         12.5200       0.004235      7.553923    0.028761      0.030271   \n",
       "15          9.7225      -0.004661      2.261235   -0.003289     -0.020428   \n",
       "16         13.6600       0.000632     43.843658   -0.049361      0.377895   \n",
       "17          3.2275       0.000732      6.458005   -0.015148      0.019773   \n",
       "18          5.8625      -0.001795      2.857909   -0.003106     -0.014712   \n",
       "19          6.7800      -0.000093      1.732203   -0.017068     -0.025496   \n",
       "20          9.8875       0.003737      2.959385   -0.001103      -0.01374   \n",
       "\n",
       "   Symmetrical_REER_Discount Conditional_REER_Discount  \n",
       "0                  -0.059051                 -0.059051  \n",
       "1                   0.001677                  0.000000  \n",
       "2                  -0.074098                 -0.074098  \n",
       "3                   0.000000                  0.000000  \n",
       "4                   0.067007                  0.000000  \n",
       "5                   0.000000                  0.000000  \n",
       "6                  -0.004617                 -0.004617  \n",
       "7                   0.035618                  0.000000  \n",
       "8                   0.048714                  0.000000  \n",
       "9                   0.083492                  0.000000  \n",
       "10                  0.017574                  0.000000  \n",
       "11                  0.171889                  0.000000  \n",
       "12                  0.000000                  0.000000  \n",
       "13                 -0.000000                  0.000000  \n",
       "14                  0.018253                  0.000000  \n",
       "15                  0.022564                  0.000000  \n",
       "16                  0.000000                  0.000000  \n",
       "17                  0.000000                  0.000000  \n",
       "18                  0.000000                  0.000000  \n",
       "19                 -0.000000                  0.000000  \n",
       "20                 -0.062743                 -0.062743  \n",
       "\n",
       "[21 rows x 22 columns]"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merged_dict4['20241206']"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9b1ae10eef1dd211dd334d27d4410d8edd672406c176deb347214f996b7e46a9"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
